\documentclass[fleqn,reqno,11pt]{article}

%========================================
% Packages
%========================================

\usepackage[]{helpers/mypackages}
%\usepackage[natbib=true,style=authoryear-comp,backend=bibtex,doi=false,url=false]{biblatex}
\bibliography{helpers/MyRefLocal}
\usepackage{helpers/myenvironments}
\usepackage{helpers/mycommands}

\usepackage{todonotes}


%========================================
% Standard Layout
%========================================

\usepackage{bigints}
\usepackage{MnSymbol}
\usepackage{a4wide}

\usepackage[T1]{fontenc}


% Itemize
\renewcommand{\labelitemi}{\large{$\mathbf{\cdot}$}}    % itemize symbols
\renewcommand{\labelitemii}{\large{$\mathbf{\cdot}$}}
\renewcommand{\labelitemiii}{\large{$\mathbf{\cdot}$}}
\renewcommand{\labelitemiv}{\large{$\mathbf{\cdot}$}}
% Description
\renewcommand{\descriptionlabel}[1]{\hspace\labelsep\textsc{#1}}

% Figure Captions
\usepackage{caption} % use corresponding myfiguresize!
\setlength{\captionmargin}{20pt}
\renewcommand{\captionfont}{\small}
\setlength{\belowcaptionskip}{7pt} % standard is 0pt

\newcommand{\myalert}[1]{\textcolor{red}{#1}}

\title{Rationality, Evolution \& the Environment}
\author{Paolo Galeazzi \& Michael Franke}
\date{current version: August 21st 2015}

\begin{document}

\textbf{some general notes and remarks and todo's}

\begin{itemize}
\item micha: let's have a term for pairs (regret type, epistemic type); I'm inclined to use ``player
  type'', but that's what you reserved for regret type; maybe use \myalert{meta-type}?
\item can we reformulate the main result (proposition 1) in terms of ``strict dominance''
  and/or strict Nash equilibrium? sometimes the proof is not ideally precise because it
  actually shows something stronger, namely strict dominance, but everything is formulated in
  terms of stability; using dominance is also better for arguments about evolutionary dynamics:
  dynamics can be attracted by states that are not evolutionarily stable (even if there is an
  ESS), but dominated strategies will die out in any case;
\item should we give definitions for ESS and NSS in the main text?
\item should we include definitions of the replicator dynamic and/or the replicator mutator
  dynamic?
\item the most important issue with this text is still that we need to motivate why we care
  about non-probabilistic beliefs and/or security strategies; everything else will fall into
  place when that is done
\item an important ingredient in our argument pro regret is that radical uncertainty could be
  exogenously given; as it stands this occurs rather ``suddenly'' in the paper and should
  ideally be prepared and motivated earlier (e.g., in Sections 2 and 3)
\item a major contribution of our paper is the ``meta-game'' approach, but in the current
  version I feel that this is not stressed sufficiently; the introduction and the beginning of
  section 3 could do a bit more to carve out this idea as something generally cool; especially
  the formula from 3.4 could occur earlier (albeit in more general notation);
\end{itemize}

\newpage


\maketitle

\section{Introduction / Motivation}
\label{sec:intr--motiv}

\todo[inline]{this is only a dummy introduction; rewrite eventually with a better focus on the
  results and main conceptual points we would like to drive home}

Evolutionary game theory has become an established philosophical tool for probing into
conceptual issues whose complexity requires mathematical modeling. However, most applications
of EGT look at evolutionary selection of behavior in a single \emph{stage game}. There are
actually two crude but common simplifications in this approach. Firstly, the stage game is
usually considered fixed, closed and immutable \citep[there are exceptions, of course, such
as][]{WordenLevin2007:Evolutionary-es, McKenzie-AlexanderSkymrs2012:Inventing-New-S}. Secondly,
what evolves are behavioral strategies for the stage game \citep[what][call the ``behavioral
gamit'']{FawcettHamblin2013:Exposing-the-be}.

It has consequently been argued that, instead of focusing on a fixed, immutable stage game and
the behavioral selection for that stage game alone, we should rather study the evolutionary
selection of \emph{choice mechanisms} that are adapted in a rich and variable environment
\citep[e.g.][]{FawcettHamblin2013:Exposing-the-be,McNamara2013:Towards-a-Riche}. However,
formal accounts of the adaptive value of choice mechanisms have focused, for the most part, on
the evolutionary benefit of learning rules
\citep[e.g.][]{ZollmanSmead2010:Plasticity-and-,SmeadZollman2013:The-Stability-o}. \todo{More
  references Harley 1981!!!, O Conor \dots}  Moreover, only little attention has been paid to
modeling the direct (game-theoretic) meta-competition between alternative choice mechanisms
\citep[see][for related criticism]{FawcettHamblin2013:Exposing-the-be}.

Here, we would therefore make two contributions to the literature on evolution of choice
mechanisms. On the conceptual side, we argue that paying attention to the evolution of
(subjective representations of) preferences matters. Since almost any reasonable learning or
decision-making process will make use of some (subjective, agent-internal (possibly
unconscious)) representation of the quality of choice options, the question of which such
representations are ecologically valuable (i.e., lead to high fitness) is central. Na\"ive
intuition might convince us that obviously preferences that veridically represent the object
fitness that evolutionary selection is based upon must surely be the best. We demonstrate that,
if we take into account how agents represent uncertainty, this na\"ive conclusion is premature.

On the methodological side, we introduce a conservative extension of standard EGT that allows
us to reuse notions such as evolutionary stability / evolutionary dynamics and yet helps us
study the evolutionary competition between choice mechanisms in a statistically variable
environment. Concretely, we look at the evolutionary competition of choice mechanisms in a
``meta-game'' that consists of the average expected payoffs of choice mechanisms when playing
arbitrary games (from a given class). In this sense, a meta-game captures (the modeller's)
assumptions about the relevant statistics of the environment in which evolutionary forces
operate.

Section~\ref{sec:rati--subj} introduces necessary concepts from formal decision and game
theory. Section \dots

\todo[inline]{add overview}

\section{Rationality, subjectivity  \& subjective regret}
\label{sec:rati--subj}

\todo[inline]{would it make sense to tighten and restructure this section a little bit? what
  about this: rationality says \emph{if} utils, beliefs and rational, then choose this; utils
  and beliefs are unobservable; in some case utils and preferences \emph{can} be tight to the
  environment (probability of a fair coin landing heads), in others no (probability of life on
  Mars); if tight to environment its frequencies and fitness that would pin down a norm for
  rational behavior, otherwise there's the danger of redescriptionism (just find some belief
  and preference that rationalizes observed behavior); \dots }

The standard definition of \textit{rationality} in economics and decision theory says that
choice is rational only if it maximizes (subjective) expected utility. Since the work by vNM
[cite], this view has been justified from the ``intuitive rationality'' of the axioms on the
subjective preference relation leading to the representability of the decision maker as an
expected utility maximizer. \todo{include axioms, or at least those that are mentioned as
  relevant later} While in the axiomatization by [vNM] the probability of the outcomes is
objectively given a priori, Savage54 provides a larger set of axioms that represent the
decision maker (DM) with both a subjective utility over outcomes \textit{and} a
\textit{subjective} probability over states of the world. Savage's axioms constitute the
foundation of subjective expected utility (SEU) theory, that is normally assumed to define the
rational behavior of economic agents.

\begin{definition}[SEU-maximization] Let $S$ be a set of states of the world, $X$ a set of
  outcomes and $A$ a set of actions. Given a probability measure $P$ on $S$ and a subjective
  utility function $u:X \rightarrow \mathbb{R} $, an action $a^*: S \rightarrow X $ is
  SEU-maximizing if $a^* \in \text{argmax}_{a_i \in A} \int_S u(a^*(s))dP(s) $. \todo{do we
    actually need outcomes for anything in this paper?}
\end{definition}


The subjectivity of preferences plays a very important
role for the present work. From an agent's standpoint, the amount $x$ of, say, money achieved does not necessarily
coincide with the amount of subjective utility attained $u(x)$. 
Historically,  the first to notice and formally argue for this difference
between objective utility (goods, money, etc.) and subjective utility (preferences) was
D. Bernoulli with the famous St. Petersburg paradox in 1738. Moreover, Bernoulli introduced the idea that a good representation of
subjective utility can be carried out in terms of an increasing concave function of objective
utility. This can be considered the birth of modern decision theory.

Empirically, many violations of Savage's (and vNM's) axioms have been consistently observed in behavioral economics. Most of the attention has been focused on the Independence Axiom and the Sure-thing Principle. Allais' paradox and Ellsberg's paradox are examples of violations of these two axioms, and they are at the origin of Prospect theory [cite] and ambiguity in decision theory [cite].

The main idea behind Ellesberg's paradox and the literature on ambiguity is that DM treats differently objective and subjective uncertainty. If the probability measure on the possible states of the world is not given a priori and not ''known'', then observed preferences leave no room to represent  DM's beliefs via a probability measure on the possible states. The most common solution is then to represent DM's beliefs with a set of probability measures instead of a single one.  

Prospect theory was introduced by Kahnemann and Tversky in
their famous paper from 1979. By means of experimental results they noticed that DM apparently acts as a risk averse agent with respect to gains and as a risk loving agent
with respect to losses. Consequently, they conjectured that the subjective utility is better
representable by an S-shaped utility function, concave in the positive domain of gains and
convex in the negative domain of losses.

More recently, other possible definitions of the subjective utility function have been proposed
and justified from a game theoretical point of view (e.g. Fehr and Schmidt, Charness and Rabin,
etc.). The central goal of these studies is to explain/describe the empirical behavior in social dilemmas
(e.g., Prisoner's dilemma, public goods game, etc.). In the same spirit of Prospect theory, by means of different subjective utility
functions it is possible to describe/match the behavior observed in game theoretical experiments and to
explain it as rational (in the sense of maximizing the subjective utility).
With this approach every behavior, no matter how far from the maximization of
objective utility, can be deemed rational if we can only find a subjective utility that
justifies that behavior as maximizing the subjective utility. The problem here is that it seems possible to consider rational everything
that is observed, given the adequate subjective utility function. The notion
of rationality almost collapses onto the observed behavior.

On the other side, other economists (Alchian, Friedman) seem to link the notion of rational choice
more tightly to the maximization of objective utility. In their classic works they argue that
profit maximization is a reasonable assumption for characterizing outcomes in a competitive
market because only firms behaving in a manner that is consistent with profit maximization will
survive in the long run. If the previous accounts of rationality looked more descriptive, this
definitely tastes more normative. In this sense, a normative notion of rationality would be tightly
related to (and almost coincide with) the maximization of objective utility, which is supposed
to drive the evolutionary process. It follows then that being normative in this sense points to an identification of rationality with maximization of objective utility.

It seems that we are stuck between two extrema: a too permissive descriptivism and a too restrictive normativism. On the one hand, if we want to have a
descriptive notion of rationality, then we can (almost) always define an appropriate
subjective utility whose maximization matches the observed behavior. On the other hand, if we
want to have a normative approach to rationality, then it seems we have to appeal to
evolutionary arguments entailing the understanding of rationality as maximization of objective
utility.

However, it has been argued that in a good theory of choice and decision making the normative
and the descriptive components should not come apart. For example, as Douglas Maclean [cite]
writes: 

\todo[inline]{personally, not a big fan of extended quotes; talks: yes, papers: don't know; is
  this dear to your heart? who's that Maclean anyway? ;-)}

\begin{quote}
The history of the subject reflects strong reasons why the theory of choice should have this dual character. [...] \\
A normative theory of choice gains credibility from its predictive and explanatory power, for although empirical success itself may not constitute much of a normative argument, the theory of rational behavior is less likely to be found objectionable if rationality turns out to be widespread. [...] But if, on the other hand, the normative theory turns out to be incompatible with the best established behavioral theory, then the verification of the normative theory will depend entirely on the intrinsic plausibility of its axioms, and that appeal must be quite strong, strong enough to make us overcome our charitable reluctance to conclude that our actual behavior is systematically irrational.
\end{quote}


There is another violation of Savage's axioms that is particularly relevant for the present work: transitivity of preferences. The first of Savage's axioms states that the preference relation is a (total) preorder, i.e., reflexive and transitive. Moreover, the preorder axiom is often referred to as the rationality axiom [cite], as to suggest that it is somehow the core of rational preferences. Violations of transitivity have been observed and studied in experimental literature [citeTversky69,etc], but can also be supported from a normative and theoretical point of view. \\
In what follows, an important focus of our work will be the role of regret in decision making. Regret theory predicts the violation of both transitivity and Independence of Irrelevant Alternatives (IIA). [CONNECTING TO Fawcett\&al: this is IIA, not independence]




\subsubsection{Regret theory} \label{sec:regreTheory}

Regret theory has been introduced in decision theory by Savage [] and Niherens [], and later developed by Bell [1982], Loomes and Sugden [1982], and Fishburn [1982] independently. Lately, Halpern and Pass [cite] show how the use of regret minimization can solve game theoretical puzzles (like the Centipede and the Traveller's dilemma) in a way that is closer to everyday intuition and empirical data. In this paper the notion of regret is defined as in [HalPass12]:

\begin{definition}[Pairwise regret] \label{defn:parwreg}
Given a simultaneous-move game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, the regret of player $i$ at profile $(a_i,a_{-i})$ is defined by: $\text{reg}(a_i,a_{-i}):= \pi_i(a_i^\$,a_{-i})-\pi_i(a_i,a_{-i}) $, where $a_i^\$ \in A_i$ denotes $i$'s best reply to action $a_{-i} $.
\end{definition}

\begin{definition}[Regret] \label{defn:regret}
Given a simultaneous-move game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, the regret of an action $a_i \in A_i$ is defined by: $\text{reg}(a_i):= \text{max}_{a_{-i}\in A_{-i}} \pi_i(a_i^\$,a_{-i})-\pi_i(a_i,a_{-i}) $.
\end{definition}

\begin{definition}[Regret minimization] \label{defn:regmin}
Given a simultaneous-move game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, an action $a^{r}_i $ is regret minimizing if $a^{r}_i \in \text{min}_{a_i} \text{max}_{a_{-i}} \pi_i(a_i^\$,a_{-i})-\pi_i(a_i,a_{-i}) $.
\end{definition}

\begin{example}[Coordination Game]
  Let us consider the coordination game in Figure \ref{coordgame1}. It is easy to see that
  $\text{reg}(I)=2$: when the other player chooses action $I$ the regret of $I$ is $0$ since
  $I$ is a best reply to $I$, and when the other player chooses $II$ the regret of $I$ is $2$
  since $\pi_i(II,II)-\pi_i(I,II)=2$. With the same reasoning, $\text{reg}(II)=1$. Two regret
  minimizing players would then choose action $II$, each getting a payoff of $2$. In this case
  regret minimization selects the Pareto-dominant Nash equilibrium. $ \medsquare $

\begin{figure}
\begin{center}%
\begin{tabular}{|c|c|c|}
\hline 
 & I & II\tabularnewline
\hline 
\hline 
I & 1;1 & 0;0\tabularnewline
\hline 
II & 0;0 & 2;2\tabularnewline
\hline 
\end{tabular}\end{center}

\protect\caption{A coordination game $G^C$}
\label{coordgame1}
\end{figure}



\end{example}



\begin{example}[The Traveller's Dilemma \citep{HalpernPass2012:Iterated-Regret}]
Let us now consider the Traveller's Dilemma case. The story behind the game goes as
follows. There are two travellers, Ann and Bob, who lost their luggages. Ann and Bob had
exactly the same luggage and they had insured the luggages with the same insurance company. The
insurance policy is that the two travellers have to separately claim a certain amount between
2\$ and 100\$ for the reimbursement, and if they both claim the same amount then they will be
reimbursed by that amount. Otherwise, if one of them claims more than the other, then the one
who claimed the higher amount will get the lower amount minus 2\$, while the one who claimed
the lower amount will get what (s)he claimed plus 2\$. The game is symmetric, and the payoff
function for both players is:
\begin{align*}
  \pi_i(a_i,a_{-i}) = \begin{cases} a_i \text{ \hspace{1cm} if } a_i = a_{-i} \\ a_i + 2 \text{
      \hspace{.4cm} if } a_i < a_{-i} \\ a_{-i} -2 \text{ \hspace{.25cm} if } a_{-i} <
    a_i \end{cases}
\end{align*}
By a simple computation we have:  $\forall a_i \in \lbrace 96\$, ..., 100\$ \rbrace \text{, } \text{reg}(a_i)=3 $ and $\forall a_i \in \lbrace 2\$, ..., 95\$ \rbrace \text{, } \text{reg}(a_i)>3$. If we now eliminate all the actions that do not minimize regret in the first place and iterate the regret minimization only on the action set $\lbrace 96\$, ..., 100\$ \rbrace$, we get that 97\$ is the action that minimize regret. Indeed, $\text{reg}(97)=2$ and $\forall a_i \in \lbrace 96\$, 98\$, 99\$, 100\$ \rbrace \text{, } \text{reg}(a_i)=3 $. Hence, one step of regret minimizing reasoning eliminates all the actions smaller than 96\$, and if we iterate the process once more the unique outcome is 97\$. Finally, it is worth noticing that the only rationalizable equilibrium of the game corresponds to the outcome $(2,2)$, that is consequently the only Nash equilibrium, the only perfect equilibrium, and the only sequential equilibrium of the game. $ \medsquare $
  
\end{example}





The meta-game perspective that we introduce in this paper can shed more light on the duality of descriptivism and normativism, and opens
some space in between the two extrema. 
By keeping the evolutionary approach we want to retain a
normative perspective on rationality, but our results show that (under certain conditions)
evolution does not necessarily lead to identifying rationality with maximization of objective
utility, contrary to the intuition of Alchian [cite] and Friedman [cite].

In the following we mainly deal with two types of agents: players whose subjective utility is defined
in terms of regret (as in DEFINITION), and players whose utility
function coincides with the objective utility $\pi_i$. 

The justification for this choice is both historical and behavioral. Among
the possible competitors of utility maximization, regret has always been in a prominent
position, both from a descriptive and normative viewpoint. Indeed, Bell82 writes:
\begin{quote}
  By explicitly incorporating regret, expected utility theory not only becomes a better
  descriptive predictor but also may become a more convincing guide for prescribing behavior to
  decision makers.
\end{quote}
In the same year, Graham Loomes and Robert Sugden \citet{LoomesSugden1982:Regret-Theory:-} show that a regret-based theory of choice can match
and explain all the main experimental results of prospect theory, and claim that
\begin{quote} [...] we shall challenge the idea that the conventional axioms [of decision
  theory] constitute the only acceptable basis for rational choice under uncertainty. We shall
  argue that it is no less rational to act in accordance with regret theory, and that
  conventional expected utility theory therefore represents an unnecessarily restrictive notion
  of rationality. \hfill \citep{LoomesSugden1982:Regret-Theory:-}
\end{quote}

\section{The model}
\label{sec:model}

\todo[inline]{first two paragraphs here are partly redundant}

We consider an evolutionary model that is different, for the best of our knowledge, from all
the standard models of evolutionary game theory. Given a game
$ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, a subjective utility over $G$ is a function
$\theta: A \rightarrow \mathbb{R} $, where $ A:=\prod_{i\in N}A_{i} $ as usual. We denote by
$ \Theta:= \mathbb{R}^{|A|} $ the set of all the subjective utilities over $G$. The model we
introduce here is a multiple game model, that we also call \textit{multi-game} or
\textit{meta-game}, where a \textit{class} $\mathcal{G}$ of fitness games is played in a
population. All the models used in evolutionary game theory that we are aware of always
consider a single game at a time. \todo{better formulate less strongly} Our extension is meant
to capture both a more general notion of environment and a more general notion of phenotype.
 
There are good reasons to claim that focusing on more general psychological mechanisms instead
of on behavior itself as the phenotype under evolutionary selection can be more faithful and
insightful for natural biology and ecology [Fawcett\&al.].  In all classical models the agents
are represented as playing a single fixed game, and as genetically predetermined to play fixed
strategies, that consequently are the only target of natural selection in those
frameworks. Standard evolutionary game theory cannot take charge of this shift of perspective
until it will keep modelling a single game at a time, and until it will keep focusing on
observed behavior only. ''Instead we should expect animals to have evolved a set of
psychological mechanisms which enable them to perform well on average across a range of
different circumstances''[Fawcett\&al.]. [maybe add evolution of preferences here]

In this work we take $\mathcal{G}$ to be the class of symmetric $2 \times 2$ games\footnote{Note that this class includes many of the most famous games extensively considered in game theoretical literature, e.g., Prisoner's dilemma, Chicken game, Stag hunt, etc.}. First, a game $G$ is selected from the class of fitness games $\mathcal{G}$, and then players in the population are matched to play the game $G$. Each player is a function $\tau: \mathcal{G} \rightarrow  \Theta$, and we call $\tau$ a \textit{player type}, or just a \textit{type}\footnote{Notice that the function $\tau$ is well-defined since, for any symmetric $2 \times 2$ game, the codomain $\Theta=\mathbb{R}^{4}$ is the same.}. Intuitively, a type can be interpreted as a way of reasoning, a pattern of conceptualization, a thread that relates different subjective utilities across different games. We denote by $T$ the class of player types. For each game $G \in \mathcal{G}$, the evolutionary fitness is determined by the objective utility (payoff) function $\pi_G$, but the player's action choice depends on the player's subjective utility function $\tau(G)$, given by the player's type $\tau$. Notice that, for any symmetric game $G$, the action sets $(A_1, \dots, A_N)$ and the payoff functions $ (\pi_1, \dots, \pi_N)  $ are the same for all $i\in \lbrace 1, \dots N \rbrace$. Consequently, we only write $ A^G $ and $ \pi^G $ for the action set and the payoff function of game $G$, respectively. Moreover, in symmetric $2 \times 2$ games we have $A=A^G \times A^G$. Then, for $x,y \in A^G$ we denote by $\pi^G(x,y)$ the objective payoff of playing action $x$ in response to action $y$.\\



\subsection{Player types}

The set of all possible player types amouts to the set of all possible functions $ \tau: \mathcal{G} \rightarrow  \Theta $, i.e., $T=\mathbb{R}^{4^{\mathbb{R}^{4}}} $ , but for the sake of simplicity we will focus on types that are relevant and meaningful from a decision-theoretic point of view. We are mainly interested in two types: the objective type and the regret type.\\
Given a game $G$ and Definition \ref{defn:parwreg}, it is straightforward to define the
\textit{regret preference} $\theta^{reg}$ and the \textit{regret type} $\tau^{reg}$ as
follows. 

\todo[inline]{can some of these definitions not be written as one? e.g., regret preference and
  regret type as one definition? seems more elegant to me, because it's less repetitive (``for
  a game ...'')}

\begin{definition}[Regret preference] \label{defn:regpref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the regret preference $ \theta^{reg}: A \rightarrow \mathbb{R} $ such that $ \theta^{reg}(a_i,a_{-i})=-\text{reg}(a_i,a_{-i}) $.\footnote{More precisely, this is the negative regret, whereas the (positive) regret, as defined in [halpass], would not have the minus sign at the beginning of the formula. Here it will be easier to define the regret in terms of negative regret.}

\end{definition}



\begin{definition}[Regret type] \label{defn:regtype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call regret type the function $\tau^{reg}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{reg}(G)= \theta^{reg}$.

\end{definition}

\noindent Similarly, let us define the \textit{objective preference} $\theta^{\pi}$ and the \textit{objective type} $ \tau^{\pi} $, that we also call $\pi$\textit{-type}, as follows. 

\begin{definition}[Objective preference] \label{defn:objpref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the objective preference $ \theta^{\pi}: A \rightarrow \mathbb{R} $ such that $ \theta^{\pi}(a_i,a_{-i})=\pi(a_i,a_{-i}) $.

\end{definition}


\begin{definition}[Objective type] \label{defn:objtype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call objective type, or $\pi$-type, the function $\tau^{\pi}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{\pi}(G)= \theta^{\pi}$.

\end{definition}

\noindent In other words, we consider two prominent player types: a type who has a veridical subjective utility that perfectly matches the objective utility (i.e., the evolutionary fitness); and a type who has a non-veridical regret-based subjective utility. 

\iffalse
(maybe we want to introduce altruistic and competitive only later) Other types of player have been studied in the literature. A famous example is the \textit{altruistic type}.

\begin{definition}[Altruistic preference] \label{defn:altpref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the altruistic preference $ \theta^{alt}: A \rightarrow \mathbb{R} $ such that $ \theta^{alt}(a_i,a_{-i})=\pi(a_i,a_{-i}) + \sum_{j \neq i} \pi(a_{j},a_{-j})$.\footnote{A more general formulation [see: REFERENCES] would be to define an $ \alpha$-altruistic type, for $\alpha \in [0,1]$, with subjective utility $ \theta^{\alpha lt}(a_i,a_{-i})=\pi(a_i,a_{-i}) + \alpha \sum_{j \neq i} \pi(a_{j},a_{-j})$. Since we are not interested in the evolution of degrees of altruism here, we simply fix $ \alpha = 1 $.}

\end{definition}

\begin{definition}[Altruistic type] \label{defn:alttype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call altruistic type the function $\tau^{alt}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{alt}(G)= \theta^{alt}$.

\end{definition}

\noindent As opposite to the altruistic type, it is possible to define a \textit{competitive type} as follows. 

\begin{definition}[Competitive preference] \label{defn:compref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the altruistic preference $ \theta^{com}: A \rightarrow \mathbb{R} $ such that $ \theta^{com}(a_i,a_{-i})=\pi(a_i,a_{-i}) - \sum_{j \neq i} \pi(a_{j},a_{-j})$.

\end{definition}

\begin{definition}[Competitive type] \label{defn:comtype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call altruistic type the function $\tau^{com}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{com}(G)= \theta^{com}$.

\end{definition}

\fi


\subsection{Epistemic types}
\label{sec:epistemic-types}

\todo[inline]{I think we really need a better (and earlier) justification for these epistemic
  types; we could appeal to information available to agents; naturalness of situations in which
  we cannot attach numbers to our beliefs (life on Mars again) \dots}

In line with traditional evolutionary game theory, the idea of this work is to model a population of rather unsophisticated and myopic agents that possibly differ from each other with respect to two components: the player type and the epistemic type.
In full generality, we think of an epistemic type as a general disposition to form beliefs about the co-playerâ€™s behavior.    Players in the population obviously face uncertainty about the composition of the population that they are part of, and consequently about the type of co-player that they are randomly paired with at each round and about the co-player's actions. We represent this uncertainty that players entertain in two different ways, a probabilistic flat belief and a non-probabilistic belief. This amounts to having two different epistemic types $e$ in the population, $e \in \lbrace \overline{\mu}, \Delta(A_{-i}) \rbrace $, where $\overline{\mu}$ is the probabilistic type and $\Delta(A_{-i})$ is the non-probabilistic type, defined as follows:

\begin{itemize}

\item $ \Delta(A_{-i}):=\lbrace \mu \in \mathbb{R}^{A_{-i}}: \sum_{a_{-i} \in A_{-i}} \mu(a_{-i}) = 1 \rbrace$;

\item $\overline{\mu} \in \lbrace \mu \in \mathbb{R}^{A_{-i}}: \sum_{a_{-i} \in A_{-i}} \mu(a_{-i}) = 1 \rbrace$ is the probability measure over the co-player's actions such that: $\forall a_{-i} \in A_{-i}$, $\overline{\mu}(a_{-i})= \frac{1}{|A_{-i}|}$.

\end{itemize} 

Hence, we consider two possible epistemic states in the face of uncertainty. The epistemic type $\Delta(A_{-i})$ represents a situation of non-probabilistic radical uncertainty, where the players are not able to narrow down the set of probability distributions over the co-player's actions and they consider all of them as possible. The other epistemic type $\overline{\mu}$ conceptualizes the uncertainty about the population by using the principle of insufficient reason and ascribes equal probability to all the possible alternatives. Both options are reasonable and justifiable ways to deal with situations of uncertainty [REFERENCES]. \\
Since for the moment we want to model populations of biologically unsophisticated players, we do not endow them with an effective learning procedure. Our players encode both a psychological subjective representation of the interaction (player type) and a conceptualization of uncertainty (epistemic type), but they are too simple to have any learning or belief updating procedure. From this point of view, we can take the learning process away from natural selection and focus on player types and epistemic types as the target of evolutionary pressure.

\subsection{Uncertainty aversion and maxmin rule}

\todo[inline]{this paragraph seems to presuppose familiarity with maxi-minimization (can we
  write this with a hyphen, any chance?); we should rewrite this or introduce the notion immediately;}

Given a player type and an epistemic type, there are different ways to produce a behavior. A
huge body of experimental literature strongly suggests that agents are generally uncertainty
(or ambiguity) averse [REF]. This pattern of behavior in the presence of ucertainty has been
famously axiomatized by Gilboa and Schmeidler in a paper from 1989. The idea is that being
uncertainty averse amounts to behaving in accordance with maximinimizing expected utility over
a set of prior probabilities. Whenever the set of priors is a singleton, maximinization of
expected utility coincides with maximization of expected utility. In line with empirical data,
we assume that players in the population are uncertainty averse and conform to maxmin expected
utility. The resulting behavior is then produced by maximinimizing over the subjective utility
given by the player type and the set of priors given by the epistemic type.

  \todo[inline]{I would like to suggest to move Figure 2 next to Figure 1; it is already useful
  for example 1 and could be referred to there already; I would suggest to use subfigures to
  put both next to each other}

\begin{example}
  Consider the game in Figure \ref{coordgame1} again. When a player characterized
  by\footnote{To ease notation in the following we will refer to a player directly as a pair
    $(player \text{ } type \text{ } \tau,\text{ } epistemic\text{ } type \text{ } e)$.} player
  type $ \tau^{reg} $ and epistemic type $ \Delta(A_{-i}) $ faces the game in Figure
  \ref{coordgame1}, her player type gives rise to the representation $\tau^{reg}(G^C)$ in
  Figure \ref{coordgame1reg}. Then, maximinimizing expected utility over the probability
  simplex $ \Delta(A_{-i}) $ given the game in Figure \ref{coordgame1reg} corresponds to
  playing the standard maxmin strategy [REF] of that game.\footnote{Notice that this is the
    case for any game: given a game $G$, maximinimizing expected utility over the probability
    simplex $ \Delta(A_{-i}) $ amounts to playing the standard maxmin strategy of $G$.} This,
  in turn, corresponds to the regret minimizing action of the original game $G^C$ of Figure
  \ref{coordgame1}, namely action $II$, as we have seen in Section \ref{sec:regreTheory}. A
  player $(\tau^{reg},\overline{\mu})$ instead has subjective representation $\tau^{reg}(G^C)$
  of Figure \ref{coordgame1reg} and a flat probability measure
  $\overline{\mu}=(\frac{1}{2}I,\frac{1}{2}II)$ over the co-player's actions. Consequently,
  such a player would play action $II$, i.e., the action that maximinimizes expected utility
  given the flat probability measure $\overline{\mu}$.\footnote{As we already noticed,
    maximinimizing expected utility given a probability measure $\mu$ is equivalent to
    maximizing expected utility given $\mu$.}  Similarly, a player
  $(\tau^{\pi},\Delta(A_{-i}))$ will have the subjective representation coinciding with the
  objective fitness game, i.e., $ \tau^{\pi}(G^C)= G^C $. Then, both actions $I$ and $II$
  maximinimize expected utility over the probability simplex $ \Delta(A_{-i}) $. Hence, a
  player $(\tau^{\pi},\Delta(A_{-i}))$ will be indifferent between $I$ and $II$, and will
  randomize with equal probability $(\frac{1}{2}I,\frac{1}{2}II)$. Finally, a player
  $(\tau^{\pi},\overline{\mu})$ maximinimizes the objective fitness game $G^C$ of Figure
  \ref{coordgame1} with flat probability $\overline{\mu}$ over the co-player's actions, i.e.,
  maximizes objective utility given $\overline{\mu}$. In game $G^C$ this yields action $II$.



\begin{figure}
\begin{center}%
\begin{tabular}{|c|c|c|}
\hline 
 & I & II\tabularnewline
\hline 
\hline 
I & 0;0 & -2;-1\tabularnewline
\hline 
II & -1;-2 & 0;0\tabularnewline
\hline 
\end{tabular}\end{center}

\protect\caption{Regret representation $\tau^{reg}(G^C)$}
\label{coordgame1reg}
\end{figure}

\end{example}

We are now in the position of deriving behavior directly from the pair $(\tau, e)$. Definitions \ref{def:utility-belief} and \ref{def:maxminSEU} simply formalize the notions of subjective expected utility and maxmin subjective expective utility, respectively. 

\begin{definition} \label{def:utility-belief}

Given a game $G$, an action $a_i \in A_i$, and a belief $\mu \in \lbrace \mu' \in \mathbb{R}^{A_{-i}}: \sum_{a_{-i} \in A_{-i}} \mu'(a_{-i}) = 1 \rbrace$, we define $\tau(G)(a_i, \mu):= \sum_{a_{-i} \in A_{-i}} \tau(G)(a_i, a_{-i}) \cdot \mu(a_{-i})$. 

\end{definition}

\begin{definition} \label{def:maxminSEU}

Given a game $G$ and a player $(\tau, e)$, we define $\text{maxmin}(\tau(G), e):= \lbrace a'_i \in A_i : a_i \in \text{max}_{a_i \in A_i} \text{ min}_{\mu \in e} \text{ } \tau(G)(a_i, \mu) \rbrace$.

\end{definition}

\noindent Definition \ref{def:expected fitness} gives the expected evolutionary fitness of player $(\tau, e)$ against player $(\tau', e')$ in game $G$.\footnote{As already specified in the previous example, we assume that, whenever the set $\text{maxmin}(\tau(G), e)$ is not a singleton, the player $(\tau, e)$ will mix with equal probability among the actions in $\text{maxmin}(\tau(G), e)$.}

\begin{definition} \label{def:expected fitness}

Given a game $G \in \mathcal{G}$, a player $(\tau, e)$, and a player $(\tau', e')$, we define $\pi^G((\tau, e),(\tau', e')):= \pi^G(\text{maxmin}(\tau(G), e),\text{maxmin}(\tau'(G), e'))$. 

\end{definition}

\todo[inline]{should we explain here, or very soon, what the resulting types really are: regret
  minimizers, maximin players \dots}

Many other alternatives different from maxmin expected utility could produce behavior: choice rules like minmax, maxmax, and minmin expected utility would similarly generate behavior from a player type and an epistemic type. Here we postulate that players are maximinimizers for two main reasons. First, our main interest is the evolution of different patterns of subjective conceptualizations of games (player types), and we want to show that the veridical representation (objective type) is not necessarily the fittest and may not be evolutionarily stable. Assuming that all players use the maxmin rule independent of their player type allows us to factor the choice rule out of the selection process and to focus on player types. Secondly, as already mentioned, among other possible choice rules maxmin is not only intuitively appealing but also corroborated from an empirical point of view.

Before concluding this section, it is worth stressing two important points.

\begin{fact} \label{fact:maxEU-minReg}

For any given single probability $\mu$, maximization of expected utility and minimization of expected regret are behaviorally equivalent.

\end{fact}

\noindent As we have seen in the previous example, this is not the case in the presence of (radical) uncertainty, in the sense of representation of belief state in terms of a set of probability, as in $ \Delta(A_{-i}) $.

\begin{fact} \label{fact:equivalence2x2}

In the class of $2 \times 2$ symmetric games, players $(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{\pi}, \overline{\mu})$, and $(\tau^{reg},\overline{\mu})$ are behaviorally equivalent.

\end{fact} 

\noindent Two remarks. Firstly, Fact \ref{fact:equivalence2x2} does not hold for $n \times n$
symmetric games in general. Secondly, we treat behaviorally equivalent types as distinct,
because we assume that what is selected by biological evolution is not choice behavior as such,
but the mechanism which generates behavior. This matters in particular if we assume that
mutations affect different components of the behavior generating mechanisms (see below). 



\subsection{Evolution \& the environment}

[MAYBE, put part of Version2 from Snippets here, if not in Introduction]

In standard evolutionary game theory a population of agents plays over a single game, that is supposed to represent the interaction driving the evolutionary dynamics. In line with [Fawcett-al.], we claim that the single-game approach is too limiting to encompass the vast variety of interactions that lead evolution. Here we propose the meta-game model in order to account for a more general notion of environment. By allowing the population to play over a class of possible games, we want to take into consideration a notion of environment that comprises a multitude of possible interactions as the driver of natural selection. In this perspective, the meta-game approach represents a model of evolution more faithful and possibly closer to reality. \\
We assume a huge, possibly infinite, population of players $(\tau,e)$. At each time, a game $G$ is selected from the class of possible games, and players are randomly paired to play $G$. At the end of the play we keep track of the evolutionary fitness achieved by each player. Next, another game $G'$ is randomly selected again, and so on. The evolutionary fitness of each player is then based on the expected objective payoff over the class $\mathcal{G}$. Denoting by $P(G)$ the probability of game $G$ to be selected, the evolutionary fitness of player $(\tau,e)$ against player $(\tau',e')$ is given by: 

$$ EF((\tau,e),(\tau',e'))= \int_G  P(G) \cdot \pi^G((\tau, e),(\tau', e')).  $$

\noindent The framework we propose here is a very neutral and flexible tool to model the notion of environment. We can take into account many different types of environment by simply changing the class $\mathcal{G}$ of possible games, and in the limit case where $\mathcal{G}$ is a sigleton our model reduces to the standard models of evolutionary game theory. 
By combining field studies and statistics, one could design a more specific class $\mathcal{G}$ with appropriate probabilities $P(G)$ in order to match the natural environment of a given population, but for our theoretical purposes we adopt another approach. As already anticipated, we take $\mathcal{G}$ to be the class of $2 \times 2$ symmetric games. More precisely, we imagine the class $\mathcal{G}$ to be generated from the generic form table of Figure \ref{generic form table}, where $a,b,c,d$ are i.i.d. random variables sampled from a finite set of natural numbers $ \lbrace \underline{n}, \dots, \overline{n}  \rbrace$.


\begin{figure}
\begin{center}%
\begin{tabular}{|c|c|c|}
\hline 
 & I & II\tabularnewline
\hline 
\hline 
I & a;a & b;c\tabularnewline
\hline 
II & c;b & d;d\tabularnewline
\hline 
\end{tabular}\end{center}

\protect\caption{generic form table for $2 \times 2$ symmetric games}
\label{generic form table}
\end{figure}






\section{Results: the basic model}
\label{sec:results:-basic-model}


In this section we present results of computer simulations and analytical proofs for our basic
model with the four player types introduced in the previous section. 

\subsection{Numerical simulations}
\label{sec:numer-simul}

Table~\ref{tab:ExpectedFitness_4Types} gives an approximation of expected fitness, obtained by
numerical simulation from averaging over $100,000$ randomly sampled games in $\mathcal{G}$ with
$a,b,c,d \in \lbrace 0, \dots, 10 \rbrace$. Concretely, games were sampled repeatedly by
choosing independently four integers $a,b,c,d \in \lbrace 0, \dots, 10 \rbrace$ uniformly at
random. For each game, a player type's action choices were determined and payoffs from all
pairwise encounters recorded. (Whenever a player type would not select a unique action in a
given game, we recorded unbiased averages over playing either action.) The number in each cell
of Table~\ref{tab:ExpectedFitness_4Types} is the average payoff for the row player type over
all 100,000 numbers for each pairing of player types obtained in this way. These averages
approximate the corresponding average evolutionary fitness of the row player when matched with
the column player.

\begin{table}[t]
\centering
\begin{tabular}{ccccc}
  \toprule
 & $\tau^{reg}, \Delta(A_{-i})$ 
 & $\tau^{\pi}, \Delta(A_{-i})$ 
 & $\tau^{reg}, \overline{\mu}$ 
 & $\tau^{\pi}, \overline{\mu}$ \\ 
  \midrule
  $\tau^{reg}, \Delta(A_{-i})$ & 6.663 & 6.662 & 6.663 & 6.663 \\ 
  $\tau^{\pi}, \Delta(A_{-i})$ & 6.486 & 6.484 & 6.486 & 6.486 \\ 
  $\tau^{reg}, \overline{\mu}$ & 6.663 & 6.662 & 6.663 & 6.663 \\  
  $\tau^{\pi}, \overline{\mu}$ & 6.663 & 6.662 & 6.663 & 6.663 \\ 
   \bottomrule
\end{tabular}                    
\caption{Average evolutionary fitness in simulations of 100,000 symmetric $2 \times 2$ games}
\label{tab:ExpectedFitness_4Types}
\end{table}

Simulation results obviously reflect Fact~\ref{fact:equivalence2x2} in that all encounters in
which types $(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{reg}, \overline{\mu})$ or
$(\tau^{\pi}, \overline{\mu})$ are substituted for one another yield identical results. More
interestingly, Table~\ref{tab:ExpectedFitness_4Types} shows that the maximin strategy
$(\tau^{\pi}, \Delta(A_{-i}))$ is strictly dominated by either of the three other strategies:
in each column (i.e., for each kind of opponent), the maximin strategy is strictly worse
than any of the three behaviorally equivalent competitors. This has a number of interesting
consequences.

Let's begin with a restricted scenario and look at more and more complex cases afterwards. If
we restrict attention to a population of radically uncertain players, i.e., where only
epistemic type $\Delta(A_{-i})$ exists, the regret type $ \tau^{reg} $ is the only
\emph{evolutionarily stable state}. An evolutionarily stable state is a state which cannot be
invaded by a small number of mutants. More strongly, since maximin play is strictly dominated,
we expect selection that is driven by expected fitness to invariably weed out maximin behavior
in favor of regret minimization. In other words, when taking average payoffs over the class of
random games looked at here, regret minimization is a better choice rule than standard maxmin
from an evolutionary point of view, despite the fact that the former, but not the letter
entertains non-veridical subjective preferences.

Next, if we look at the competition between all four types represented in
Table~\ref{tab:ExpectedFitness_4Types}, $(\tau^{reg}, \Delta(A_{-i}))$ is no longer
evolutionarily stable. Rather, given behavioral equivalence (Fact~\ref{fact:equivalence2x2}),
types $(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{reg}, \overline{\mu})$, and
$(\tau^{\pi}, \overline{\mu})$ are all \emph{neutrally stable}
\citep{Maynard-Smith1982:Evolution-and-t}. But since $(\tau^{\pi}, \Delta(A_{-i}))$ is strictly
dominated and so disfavored by fitness-based selection, we are still drawn to conclude that
maximin behavior is weeded out in favor of a population with a random distribution of the
remaining three types.

Simulation results of the (discrete time) \emph{replicator dynamics}
\citep{TaylorJonker1978:Evolutionary-St} indeed show that random initial population
configurations are attracted to states with only three player types:
$\tuple{\tau^{reg}, \Delta(A)}$, $\tuple{\tau^{reg}, \bar{\mu}}$ and
$\tuple{\tau^{\pi}, \bar{\mu}}$. The relative proportions of these depend on the initial
population.\todo{check uniform notation for player types: round vs.~square brackets} This
variability disappears if we add a small mutation rate to the dynamics. We assume a fixed,
small mutation rate $\epsilon$ for the probability that a player's preference type \emph{or}
her epistemic type changes to another random preference type or epistemic type. The probability
that a player type randomly mutates into a completely different player type with altogether
different preference type and epistemic type would then be $\epsilon^2$. With these assumptions
about ``component-wise mutations'', numerical simulations of the (discrete time)
\emph{replicator mutator dynamics} \citep{Nowak2006:Evolutionary-Dy} show that already for very
small mutation rates almost all initial populations converge to a single fixed point in which
the majority of players are regret types. For instance, with $\epsilon = 0.001$, almost all
initial populations are attracted to a final distribution with proportions:\todo{recalculate
  these numbers for the actual 4x4 game!}

\begin{center}
  \begin{tabular}{ccc}
    $\tuple{\tau^{reg}, \Delta(A)}$ & $\tuple{\tau^{reg},
      \bar{\mu}}$ & $\tuple{\tau^{\pi}, \bar{\mu}}$ \\ \hline
    0.279  &   0.383 &    0.281 
  \end{tabular}
\end{center}

What this suggests is that, since biological evolution selects behavior-generating mechanisms,
not behavior as such, it need not be the case that behaviorally equivalent mechanisms are
treated equally all the while. If mutation probabilities are a function of individual
components of such behavior-generating mechanisms, it can be the case that certain components
are more strongly favored by a process of random mutation and selection. This is exactly the
case with regret-based subjective preferences in the present example. Since regret-based
subjective preferences are much better in connection with radical uncertainty than veridical
preferences are, the proportion of expected regret minimizers in the attracting state is
substantially higher than that of expected utility maximizers, even though these types are
behaviorally equivalent. In sum, component-wise mutation could have lead to a majority of
regret-based players even if they are behaviorally indiscernible from decision makers with
veridical preferences, because regret types are better off under radical uncertainty.

\subsection{Analytical results}
\label{sec:analytical-results}

Results based on the single meta-game in Table~\ref{tab:ExpectedFitness_4Types}, which was
obtained by averaging over numerical simulations, are not fully general and possibly spoiled by
random fluctuations in the sampling procedure. Fortunately, for the case of symmetric
$2 \times 2$ games, the main result that maximin types $(\tau^{\pi}, \Delta(A_{-i}))$ are
strictly dominated can also be shown analytically for generous general conditions on how likely
randomly sampled games are.

\begin{proposition} \label{proposition1}

  Let $\Lambda = \lbrace (\tau^{\pi}, \Delta(A_{-i})), (\tau^{reg}, \Delta(A_{-i})) \rbrace$ be
  the set of possible meta-types $(\tau, e)$ in the population, and let $\mathcal{G}$ be the class
  of symmetric $2 \times 2$ games with payoffs sampled from a finite, or compact and convex,
  set of i.i.d.~values. Then, $(\tau^{reg}, \Delta(A_{-i}))$ is the only strict Nash
  equilibrium in the resulting meta-game.

\end{proposition}

\begin{proof}
See Appendix.
\end{proof}

From Fact \ref{fact:equivalence2x2} and Proposition \ref{proposition1} the following corollary follows.

\begin{corollary} \label{corollary1}

  Fix $T = \lbrace \tau^{\pi}, \tau^{reg} \rbrace$,
  $E = \lbrace \Delta(A_{-i}), \overline{\mu} \rbrace$, $\Lambda= T \times E$, and
  $\mathcal{G}$ the class of symmetric $2 \times 2$ games with payoffs sampled from a finite,
  or compact and convex, set of i.i.d. values. Then, player type $(\tau^{\pi}, \Delta(A_{-i}))$
  is strictly dominated by $(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{\pi}, \overline{\mu})$, and
  $(\tau^{reg}, \overline{\mu})$.

\end{corollary}

\begin{proof}
See Appendix.
\end{proof}

Corollary~\ref{corollary1} tells us that the conclusions drawn in the previous section based on
the meta-game in Table~\ref{tab:ExpectedFitness_4Types} hold more generally for any class of
games in which the probability of encountering a game is the product of independently sampling
four identically distributed payoff values. As before, player types
$(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{\pi}, \overline{\mu})$, and
$(\tau^{reg}, \overline{\mu})$ will be neutrally stable, and fitness-based selection will tend
to weed out maximin play and leave us with a population of arbitrary frequency of
$(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{\pi}, \overline{\mu})$, and
$(\tau^{reg}, \overline{\mu})$ meta-types.

This shows that there is support for the main conceptual point that we wanted to make:
non-veridical subjective preference relations \emph{can}, under specific circumstances, persist
under evolutionary selection based on objective fitness. Moreover, regret-based preferences can
not only persist, but even be favored by natural selection if agents are radically
uncertain. This holds generally for playing arbitrary $2 \times 2$ games whose payoffs are
sampled identically and independently at random.

\section{Extensions}
\label{sec:extensions}

How do the basic results from the previous section carry over to more encompassing, richer
models? Section~\ref{sec:more-types} first considers further conceptually interesting
preference types that have been suggested in the recent literature. Section~\ref{sec:n-times-n}
then considers the case of $n \times n$ games for $n \ge 2$. Finally, to put our results into
the proper perspective, Section~\ref{sec:solitary-decisions} ends with a brief comparison of
game situations with cases of solitary decision making.

\subsection{More types}
\label{sec:more-types}


In evolutionary game theory other types of player have been investigated. A famous example is the \textit{altruistic type} [REF], introduced in the literature in order to explain the possible survival of altruistic behavior. In our framework, we can represent the altruistic type as follows. 

\begin{definition}[Altruistic preference] \label{defn:altpref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the altruistic preference $ \theta^{alt}: A \rightarrow \mathbb{R} $ such that $ \theta^{alt}(a_i,a_{-i})=\pi(a_i,a_{-i}) + \sum_{j \neq i} \pi(a_{j},a_{-j})$.\footnote{A more general formulation [see: REFERENCES] would be to define an $ \alpha$-altruistic type, for $\alpha \in [0,1]$, with subjective utility $ \theta^{\alpha lt}(a_i,a_{-i})=\pi(a_i,a_{-i}) + \alpha \sum_{j \neq i} \pi(a_{j},a_{-j})$. Since we are not interested in the evolution of degrees of altruism here, we simply fix $ \alpha = 1 $.}

\end{definition}

\begin{definition}[Altruistic type] \label{defn:alttype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call altruistic type the function $\tau^{alt}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{alt}(G)= \theta^{alt}$.

\end{definition}

\noindent As opposite to the altruistic type, it is possible to define a \textit{competitive type}. 

\begin{definition}[Competitive preference] \label{defn:compref}

For a game $ G=\langle N, (A_i , \pi_i)_{i \in N} \rangle $, we define the altruistic preference $ \theta^{com}: A \rightarrow \mathbb{R} $ such that $ \theta^{com}(a_i,a_{-i})=\pi(a_i,a_{-i}) - \sum_{j \neq i} \pi(a_{j},a_{-j})$.

\end{definition}

\begin{definition}[Competitive type] \label{defn:comtype}

Given $ \mathcal{G} $ the class of symmetric $ 2 \times 2 $ games, we call altruistic type the function $\tau^{com}: \mathcal{G} \rightarrow  \Theta$ such that, for all $G \in \mathcal{G}$, $ \tau^{com}(G)= \theta^{com}$.

\end{definition}

Similarly to the evolutionary competition that we simulated before, we can study the
evolutionary fitness of this extended set of players when they are all represented in the
population. Table~\ref{tab:ExpectedFitness_2x2_Full} shows simulation results that approximate the
expected fitness in the relevant meta-game.

\begin{table}[]
\centering
\footnotesize
\begin{tabular}{ccccccccc}
  \hline
 & $\tuple{\tau^{reg}, \Delta(A)}$ 
 & $\tuple{\tau^{\pi}, \Delta(A)}$ 
 & $\tuple{\tau^{com}, \Delta(A)}$
 & $\tuple{\tau^{alt}, \Delta(A)}$
 & $\tuple{\tau^{reg}, \bar{\mu}}$ 
 & $\tuple{\tau^{\pi}, \bar{\mu}}$ 
 & $\tuple{\tau^{com}, \bar{\mu}}$
 & $\tuple{\tau^{alt}, \bar{\mu}}$ \\ 
  \hline
  $\tuple{\tau^{reg}, \Delta(A)}$ & 6.663 & 6.662 & 5.829 & 7.105 & 6.663 & 6.663 & 5.829 & 7.489 \\
  $\tuple{\tau^{\pi}, \Delta(A)}$ & 6.486 & 6.484 & 6.088 & 6.703 & 6.486 & 6.486 & 6.088 & 6.875 \\
  $\tuple{\tau^{com}, \Delta(A)}$ & 6.323 & 6.758 & 5.496 & 6.977 & 6.323 & 6.323 & 5.496 & 7.149 \\
  $\tuple{\tau^{alt}, \Delta(A)}$ & 5.949 & 5.722 & 5.326 & 6.396 & 5.949 & 5.949 & 5.326 & 6.568 \\
  $\tuple{\tau^{reg}, \bar{\mu}}$ & 6.663 & 6.662 & 5.829 & 7.105 & 6.663 & 6.663 & 5.829 & 7.489 \\
  $\tuple{\tau^{\pi}, \bar{\mu}}$ & 6.663 & 6.662 & 5.829 & 7.105 & 6.663 & 6.663 & 5.829 & 7.489 \\
  $\tuple{\tau^{com}, \bar{\mu}}$ & 6.323 & 6.758 & 5.496 & 6.977 & 6.323 & 6.323 & 5.496 & 7.149 \\
  $\tuple{\tau^{alt}, \bar{\mu}}$ & 6.331 & 5.893 & 5.497 & 6.566 & 6.331 & 6.331 & 5.497 & 7.152 \\
   \hline                          
\end{tabular}                      
\caption{Average payoff in simulations of 100,000
  randomly generated $2 \times 2$ symmetric games.}
\label{tab:ExpectedFitness_2x2_Full}        
\end{table}   
 
\todo[inline]{is it true that competitive preferences types are behaviorally equivalent under
  either epistemic type? can we show that?}
 
The approximations in Table~\ref{tab:ExpectedFitness_2x2_Full} confirm basic intuitions about
altruistic and competitive types: averaging over randomly sampled games, everybody would like
to have an altruistic opponent and nobody would like to play against a competitive
opponent. Perhaps more surprisingly, altruistic types come up strictly dominated by competitive
types, but competitive types themselves are worse off against all opponent types except against
maximin players $\tuple{\tau^{\pi}, \Delta(A)}$ than any of the behaviorally equivalent types
$(\tau^{reg}, \Delta(A_{-i}))$, $(\tau^{\pi}, \overline{\mu})$, and
$(\tau^{reg}, \overline{\mu})$.  This is a noteworthy results in the light of the fact that
evolving altruistic preferences have been shown to support cooperative behavior in a single
stage game \myalert{[CITE]}. \todo{@Paolo: check whether this is true, please!} In contrast,
averaging over payoffs in multiple stage games, like we do here, makes altruistic preferences
prime victims of evolutionary eradication.

It is easy to see then that the previous result still obtains for the larger meta-game in
Table~\ref{tab:ExpectedFitness_2x2_Full}: $(\tau^{reg}, \Delta(A_{-i}))$,
$(\tau^{\pi}, \overline{\mu})$, and $(\tau^{reg}, \overline{\mu})$ are still neutrally stable;
all simulations of the (discrete-time) replicator dynamic on the $8 \times 8$ meta-game from
Table~\ref{tab:ExpectedFitness_2x2_Full} end up in populations consisting of only these types
in arbitrary proportion.

The following proposition (partially) confirms this result.\todo{rephrase to acknowledge all
  epistemic types?}

\begin{proposition} \label{proposition2}

Fix $\Lambda = \lbrace (\tau^{\pi}, \Delta(A_{-i})), (\tau^{reg}, \Delta(A_{-i})), (\tau^{alt}, \Delta(A_{-i})), (\tau^{com}, \Delta(A_{-i})) \rbrace$ and $\mathcal{G}$ the class of symmetric $2 \times 2$ games with payoffs sampled from a finite, or compact and convex, set of i.i.d. values. Then, $(\tau^{reg}, \Delta(A_{-i}))$ is the only evolutionarily stable player in the population.

\end{proposition}

\begin{proof}
See Appendix.\todo{is this there already?}
\end{proof}

In sum, the presence of other plausible preference types, such as competitive and altruistic
types does not undermine the previous results about the evolutionary drive towards regret-based
subjective preferences.


                                   
\subsection{$n \times n$ symmetric games}
\label{sec:n-times-n}

Results from Section~\ref{sec:results:-basic-model} relied heavily on
Fact~\ref{fact:equivalence2x2} that, for the special case of $2 \times 2$ symmetric games,
regret minimization $\tuple{\tau^{reg}, \Delta(A)}$ is behaviorally equivalent with expected
regret minimization $\tuple{\tau^{reg}, \bar{\mu}}$ and expected utility maximization
$\tuple{\tau^{\pi}, \bar{\mu}}$. This is no longer true when we look at arbitrary $n \times n$
games with $n \ge 2$. We should therefore see what happens in a broader class of games.

Table~\ref{tab:ExpectedFitness_10x10} therefore gives approximations for expected fitness in a
meta-game over a class of $n \times n$ symmetric games where $n$ is randomly drawn from
$\set{2, \dots, 10}$. Concretely, the numbers in Table~\ref{tab:ExpectedFitness_10x10} are
averages of payoffs obtained in 100,000 randomly sampled games, where each game was sampled by
first picking a number of acts $n \in \set{2, \dots, 10}$ uniformly at random, and then filling
the resulting $n \times n$ payoff matrix of the stage game with i.i.d.~sampled payoffs as
before.


\begin{table}[]
\centering
\footnotesize
\begin{tabular}{ccccccccc}
  \toprule
 & $\tuple{\tau^{reg}, \Delta(A)}$ 
 & $\tuple{\tau^{\pi}, \Delta(A)}$ 
 & $\tuple{\tau^{com}, \Delta(A)}$
 & $\tuple{\tau^{alt}, \Delta(A)}$
 & $\tuple{\tau^{reg}, \bar{\mu}}$ 
 & $\tuple{\tau^{\pi}, \bar{\mu}}$ 
 & $\tuple{\tau^{com}, \bar{\mu}}$
 & $\tuple{\tau^{alt}, \bar{\mu}}$ \\ 
  \midrule
  $\tuple{\tau^{reg}, \Delta(A)}$ & 6.567 & 6.570 & 5.650 & 6.992 & 6.564 & 6.564 & 5.593 & 7.409 \\
  $\tuple{\tau^{\pi}, \Delta(A)}$ & 6.476 & 6.483 & 5.896 & 6.818 & 6.484 & 6.484 & 5.850 & 7.124 \\
  $\tuple{\tau^{com}, \Delta(A)}$ & 6.468 & 6.647 & 5.512 & 7.169 & 6.578 & 6.578 & 5.577 & 7.354 \\
  $\tuple{\tau^{alt}, \Delta(A)}$ & 5.968 & 5.923 & 5.363 & 6.685 & 5.975 & 5.975 & 5.086 & 6.973 \\
  $\tuple{\tau^{reg}, \bar{\mu}}$ & 6.908 & 6.918 & 5.988 & 7.456 & 6.929 & 6.929 & 5.934 & 7.783 \\
  $\tuple{\tau^{\pi}, \bar{\mu}}$ & 6.908 & 6.918 & 5.988 & 7.456 & 6.929 & 6.929 & 5.934 & 7.783 \\
  $\tuple{\tau^{com}, \bar{\mu}}$ & 6.529 & 6.680 & 5.445 & 7.276 & 6.542 & 6.542 & 5.521 & 7.440 \\
  $\tuple{\tau^{alt}, \bar{\mu}}$ & 6.450 & 6.337 & 5.772 & 6.978 & 6.457 & 6.457 & 5.479 & 7.500 \\
   \bottomrule                         
\end{tabular}                      
\caption{Average payoff in simulations of 100,000
  randomly generated $n \times n$ symmetric games with $n$ randomly drawn from $\set{2, \dots, 10}$.}
\label{tab:ExpectedFitness_10x10}        
\end{table}

As is to be expected, average payoffs obtained in games with more than 2 acts are higher, as
can be seen by comparing Table~\ref{tab:ExpectedFitness_10x10} with
Table~\ref{tab:ExpectedFitness_2x2_Full}. But increases in approximate expected fitness are not
uniform. Most importantly, the regret minimizing type $\tuple{\tau^{reg}, \Delta(A)}$ is
strictly dominated by $\tuple{\tau^{reg}, \bar{\mu}}$ and by $\tuple{\tau^{\pi}, \bar{\mu}}$ in
the meta-game from Table~\ref{tab:ExpectedFitness_10x10}. This means that while regret
minimization \emph{can} thrive in some evolutionary contexts, there are also contexts where it
is demonstrably worse off.

Still, although this may be bad news for regret minimizing types
$\tuple{\tau^{reg}, \Delta(A)}$, it is not the case that regret types \emph{as such} are weeded
out by selection. Since, by Fact~\ref{fact:maxEU-minReg}, $\tuple{\tau^{reg}, \bar{\mu}}$ and
$\tuple{\tau^{\pi}, \bar{\mu}}$ are generally behaviorally equivalent, it remains that
selection based on meta-games constructed from $n \times n$ games will still not eradicate all
regret types. So, although regret types may not be selected for in this case, they are also not
selected against.

On the other hand, there are plenty of ways in which the basic insight from
Proposition~\ref{proposition1} that regret-based preferences can be strictly better than
veridical objective preferences in case of radical uncertainty could make for situations in
which evolution would select for regret types exclusively, even in $n \times n$ games. If, for
example, epistemic types of players are not what biological evolution selects, but rather
something that the particular choice situation would exogenously give us, then regret-based
preference \emph{can} again drive out veridical preferences altogether. For concreteness,
suppose that only preference types compete and that agents' epistemic types are exogenously
given, in such a way that agents hold flat probabilistic beliefs $\bar{\mu}$ with probability
$1-p$ and are of type $\Delta(A)$ with probability $p$. This transforms the meta-game from
Table~\ref{tab:ExpectedFitness_10x10} into the simpler $4 \times 4$ game in which the payoff
obtained for a preference type is the weighted average over the payoffs of that preference
types in Table~\ref{tab:ExpectedFitness_10x10}. Setting $p = 0.02$ for illustration, we get the
meta-game in Table~\ref{tab:ExogeneousEpistemics}. 

\begin{table}[]
\centering
\begin{tabular}{ccccc}
  \toprule
  & $\tau^{reg}$ 
  & $\tau^{\pi}$ 
  & $\tau^{com}$
  & $\tau^{alt}$ \\ 
  \midrule
  $\tau^{reg} $ & 6.926 & 6.926 & 5.942 & 7.757 \\ 
  $\tau^{\pi} $ & 6.924 & 6.924 & 5.948 & 7.751 \\ 
  $\tau^{com }$ & 6.566 & 6.570 & 5.481 & 7.434 \\ 
  $\tau^{alt} $ & 6.463 & 6.461 & 5.478 & 7.469 \\ 
   \bottomrule
\end{tabular}
\caption{Meta-game for the evolutionary competition between preference types when epistemic types are exogenously
  given}
\label{tab:ExogeneousEpistemics}
\end{table}

The only evolutionarily stable state of this meta-game is the regret type. Accordingly, all of
our simulation runs of the (discrete-time) replicator dynamic converged to monomorphic
regret-type populations. The reason why regret types prosper is because they have a substantial
payoff advantage if paired with radical uncertainty. If radical uncertainty is exogenously
given as something unavoidable that happens to agents (e.g., whenever they really have no
indication as to what the situation holds for them), and even if that happens only very
infrequently (i.e., for rather low $p$), regret types \emph{can} outperform veridical
preference types, as well as competitive and altruistic types.


\subsection{Solitary decisions}
\label{sec:solitary-decisions}

\todo[inline]{text in this section and the next is rough and unpolished, only intended to have
  the basic results recorded, so that we can reshape the article around the basic results}

To see how preference types behave in evolutionary competition based on solitary decision
problems, we approximated, much in the spirit of meta-games, average accumulated payoffs
obtained in randomly generated solitary decision problems. For our purposes, a decision problem
$\tuple{\States, \Acts, \Utils}$ consists of a set of world states $\States$, a set of acts
$\Acts$, and a utility function $\Utils \mycolon \States \times \Acts \rightarrow
\mathbb{R}$.
We generated arbitrary decision problems by selecting numbers of states and acts
$n_\state, n_\act \in \set{2, \dots, 10}$ and then filling the utility table, so to speak, by
independently picking a number $\Utils(\state, \act) \in \set{0, 10}$ uniformly at random, just
as we did before with symmetric games. Unlike with two-player games, we need to also sample the
actual state of the world, which we selected uniformly at random from the available states in
the current decision problem. Player types, consisting of epistemic types $\bar{\mu}$ and
$\Delta(\States)$ and preference types $\tau^{reg}$ and $\tau^{\pi}$, give rise to behavior in
the same way as before. (It is obviously not possible to carry altruistic or competitive
preference types over to solitary decision making.) As before, we recorded the behavioral
decisions for each of the four relevant player types in each sampled decision problem, and
determined the actual payoff obtained, given the actual state. Average payoff over 100,000 decision
problems are given in Table~\ref{tab:SolitaryDecisions}.

\begin{table}
  \centering
  \begin{tabular}{cccc}
    \toprule
   $\tuple{\tau^{reg}, \Delta(A)}$ 
 & $\tuple{\tau^{\pi}, \Delta(A)}$ 
 & $\tuple{\tau^{reg}, \bar{\mu}}$ 
 & $\tuple{\tau^{\pi}, \bar{\mu}}$ 
 \\ \midrule
    6.318 & 6.237 & 6.661 & 6.661 \\ \bottomrule
  \end{tabular}
  \caption{Average payoffs over 100,000 simulated solitary decision problems}
  \label{tab:SolitaryDecisions}
\end{table}

Facts~\ref{fact:maxEU-minReg} and \ref{fact:equivalence2x2} still apply:
$\tuple{\tau^{reg}, \bar{\mu}}$ and $\tuple{\tau^{\pi}, \bar{\mu}}$ are behaviorally equivalent
in general, and $\tuple{\tau^{reg}, \Delta(A)}$ is behaviorally equivalent to the former two in
decision problems with 2 states and 2 acts. \todo{show this?} We see this in part in the
results in Table~\ref{tab:SolitaryDecisions} in that the averages for $\tuple{\tau^{reg},
  \bar{\mu}}$ and $\tuple{\tau^{\pi}, \bar{\mu}}$ are identical. But since we included decision
problems with more acts and more states as well, the averages for regret minimizers
$\tuple{\tau^{reg}, \Delta(A)}$ are not identical. They are, in fact, lower, but not as low as
those of the minimax choosers. 

What that means is that basically every relevant result about game situations is also borne out
when reasoning about solitary decisions. Evolutionary selection based on objective fitness will
not select against regret-based subjective preferences, as these are indistinguishable from
veridical preferences when paired with probabilistic beliefs. But when paired with
non-probabilistic belief types, regret-based preferences actually outperform veridical
preferences. Consequently, if there is a chance, however small, that agents must fall back onto
non-probabilistic beliefs, evolution will actually positively select for non-veridical
regret-based preferences.

\subsection{Arbitrary probabilistic beliefs}
\label{sec:arbitr-prob-beli}

So far, we have assumed that epistemic types $\bar{\mu}$ hold an unbiased, flat belief. It is
worthwhile considering what happens when this assumption is relaxed and we allow agents with
probabilistic beliefs to make use of the full spectrum of probabilistic beliefs. It should be
clear that quality of beliefs directly impacts prospects of successful decision-making: if a
decision maker knows the actual state, or can put a high level of credence on the actual state,
accumulated fitness can be expected to be high. We see this, unsurprisingly, in numerical
simulations. We looked at the average payoff accumulated in 100,000 decision problems sampled
as before, except that for belief types with probabilistic beliefs we sampled a random
probabilistic belief $p$ (from an unbiased Dirichlet distribution) and chose the actual world
state with probability weights $p$. This effectively implements a bias for beliefs of the
decision maker that tend to put more weight on the actual state (although the procedure does
admittedly perverse the natural chicken-and-egg logic in this case that the actual world state
should come first and beliefs be a function of it). As a result, the average payoffs of types
$\tuple{\tau^{reg}, \bar{\mu}}$ and $\tuple{\tau^{\pi}, \bar{\mu}}$ are still the exact same
(because we compare what agents with different preference types would do under the same
beliefs; we are not interested in statistical fluctuations given one type better beliefs by
pure happenstance), but with $7.125$ notably higher than before. In effect, better
probabilistic beliefs lead to better decisions. If agents can learn, reason and extrapolate to
form better probabilistic beliefs, that will help them whenever they take their beliefs into
account. 

But this is orthogonal to the arguments in this paper, where the focus is on possibilities for
the evolution of non-veridical preferences. We know from Fact~\ref{fact:maxEU-minReg} that
regret types and veridical preference types, when paired with probabilistic belief types that
maximize/minimize expectations, are behaviorally equivalent, \emph{no matter what they believe},
as long as they belief the same. So, if learning, insight and statistical knowledge of a
recurrent situation \emph{can} be brought to bear, this will not make evolution select against
regret-based preferences. If, on the other hand, agents have no basis for probabilistic
beliefs, then we have shown that there are general and basic circumstances in which
regret-based preferences can actually be selected, despite their non-veridicality.

\section{Discussion}

\begin{itemize}
\item what we achieved
\item what could be done next
\end{itemize}



\appendix


\section{Proofs}

The proof of Proposition 1 relies on a partition of $\mathcal{G}$,
and on some lemmas. For brevity, let us denote the regret minimizer
by RM and the maximinimizer by MM. Since the proof is very long and
all the other cases are similar and easier to prove, we focus here
on the case of RM against MM players: we prove that RM is evolutionarily
stable against MM, but MM is not evolutionarily stable against RM. By $EU_{\mathcal{G}}(x,y)$ we denote the expected \textit{objective} utility (or payoff), in terms
of evolutionary fitness, of player type $x$ against player type $y$
with respect to the class of fitness games $\mathcal{G}$. 

\medskip{}


\textbf{Proof of Proposition 1.} By definition of evolutionary stability, we have to
show that in the class $\mathcal{G}$ of symmetric $2\times2$ games generated by i.i.d. sampling
from a finite or compact and convex set of values, it holds:
\begin{itemize}
\item[(i)] $EU_{\mathcal{G}}(RM,RM)>EU_{\mathcal{G}}(MM,RM);$
\item[(ii)] $EU_{\mathcal{G}}(MM,MM)<EU_{\mathcal{G}}(RM,MM).$
\end{itemize}


\noindent To show
the result we will use the following partition of $\mathcal{G}$.
\begin{enumerate}
\item Coordination games $\mathcal{G}^{C}$: $a>c$ and $d>b$;
\item Anti-coordination games $\mathcal{G}^{A}$: $a<c$ and $d<b$;
\item Strong dominance games $\mathcal{G}^{S}$: aut $(a>c$ and $b>d)$
aut $(a<c$ and $b<d)$;
\item Weak dominance games $\mathcal{G}^{W}$: aut $a=c$ aut $b=d$;
\item Indifferent games $\mathcal{G}^{I}$: $a=c$ and $b=d$.
\end{enumerate}
Before proving the lemmas, it is convenient to fix some notation.
We denote by $G^{C}$ a coordination game in $\mathcal{G}^{C}$ with
payoffs $a^{G^{C}}$, $b^{G^{C}}$, $c^{G^{C}}$, and $d^{G^{C}}$;
similarly, for $G^{A}$, $G^{S}$, $G^{W}$, and $G^{I}$. Let us
call $I_{G^{C}}^{RM}$ the event that a RM player plays action $I$
in the game $G^{C}$; and similarly for action $II$, for player MM,
and for games $G^{A}$, $G^{S}$, $G^{W}$ and $G^{I}$. Moreover,
let us recall the definition of evolutionarily stable strategy and
neutrally stable strategy.

\medskip{}

\begin{definition}[ESS-NSS]
A strategy $s^{\$}$ is \emph{evolutionarily stable
(ESS)} if for any other strategy $s$:
\begin{enumerate}
\item $\pi(s^{\$},s^{\$})>\pi(s,s^{\$})$, or
\item $\pi(s^{\$},s^{\$})=\pi(s,s^{\$})$ and $\pi(s^{\$},s)>\pi(s,s)$.
\end{enumerate}
\noindent A strategy $s^{\$}$ is \emph{neutrally stable (NSS)} if
for any other strategy $s$:
\begin{enumerate}
\item $\pi(s^{\$},s^{\$})>\pi(s,s^{\$})$, or
\item $\pi(s^{\$},s^{\$})=\pi(s,s^{\$})$ and $\pi(s^{\$},s)\geq\pi(s,s)$.
\end{enumerate}
\end{definition}

\medskip{}

\begin{lemma}
RM and MM perform equally well in $\mathcal{G}^{S}$
and in $\mathcal{G}^{I}$. 
\end{lemma}

\begin{proof}
By definition of regret minimization and maximin it
is easy to check that whenever in a game there is a strongly dominant
action $a^{\$}$, then $a^{\$}$ is both the maximin action and the
regret minimizing action. Then, for all the games in $\mathcal{G}^{S}$,
a RM chooses action $a$ if and only if MM chooses action $a$. Consequently,
RM and MM always perform equally (well) in $\mathcal{G}^{S}$. In
the case of $\mathcal{G}^{I}$ it is trivial to see that all the players
perform equally.
\end{proof}

\medskip{}

\begin{lemma}
In $\mathcal{G}^{W}$ RM is evolutionarily stable
against MM, but MM is not evolutionarily stable against RM.
\end{lemma}

\begin{proof}
Assume without loss of generality that $b=d$. We have
two cases then: (i) $c<b=d$; (ii) $c>b=d$. In the first case it
is easy to see that RM and MM perform equally well. Indeed, given
(i) both MM and RM choose action $I$ if $a>c$, and action $II$
if $c>a$. If case (ii) holds instead, we have that RM plays $I$
if $a>c$ and $II$ if $c>a$ as before, but MM plays $(\frac{1}{2}I;\frac{1}{2}II)$,
since both $I$ and $II$ maximize the minimal payoff. Consider now
a population of RM and MM playing games from the class $\mathcal{G}^{W}$.
Whenever (i) is the case both RM and MM perform equally. Suppose that
(ii) is the case and that $a>c$, without loss of generality. Then,
a RM population is evolutionarily stable against MM by condition 1
of ESS, since $a>\frac{1}{2}a+\frac{1}{2}c$, whereas a MM population
is not evolutionarily stable against RM, because clearly $\frac{1}{4}a+\frac{1}{4}b+\frac{1}{4}c+\frac{1}{4}d<\frac{1}{2}a+\frac{1}{2}b$.
Hence, we have that in general $EU_{\mathcal{G}^{W}}(RM,RM)>EU_{\mathcal{G}^{W}}(MM,RM),\mbox{ and }EU_{\mathcal{G}^{W}}(MM,MM)<EU_{\mathcal{G}^{W}}(RM,MM)$.
\end{proof}

\medskip{}


Since it is not difficult to see that both RM and MM are evolutionarily
stable in $\mathcal{G}^{C}$, and that both RM and MM are not evolutionarily
stable in $\mathcal{G}^{A}$ against each other, the main part of
the proof will be to show that RM is the only evolutionarily stable
player in the class $\mathcal{G}^{C}\cup\mathcal{G^{A}}$, that is:
\begin{itemize}
\item[(i')] $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,RM)>EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,RM),$
\item[(ii')] $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,MM)<EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,MM).$
\end{itemize}


\noindent This part needs some more lemmas to be proven, but firstly we introduce
the following bijective function $\phi$ between coordination and
anti-coordination games.

\medskip{}

\begin{definition}[$\phi$]
$\phi:\mathcal{G}^{C}\rightarrow\mathcal{G^{A}}$,
such that $\phi(a,b,c,d)=(c,d,a,b)$, is a bijection that for each
coordination game $G^{C}\in\mathcal{G}^{C}$ with payoffs $(a^{G^{C}},b^{G^{C}},c^{G^{C}},d^{G^{C}})$
gives the anti-coordination game $G^{A}\in\mathcal{G}^{A}$ with payoffs
$(a^{G^{A}},b^{G^{A}},c^{G^{A}},d^{G^{A}})=(c^{G^{C}},d^{G^{C}},a^{G^{C}},b^{G^{C}})$.
\end{definition}

\medskip{}

\begin{lemma}
Let $P(E)$ be the probability of event $E$, then
it holds that:
\begin{itemize}
\item $P(I_{G^{C}}^{RM})=P(II_{\phi(G^{C})}^{RM})$, and $P(II_{G^{C}}^{RM})=P(I_{\phi(G^{C})}^{RM})$;
\item $P(I_{G^{C}}^{MM})=P(II_{\phi(G^{C})}^{MM})$, and $P(II_{G^{C}}^{MM})=P(I_{\phi(G^{C})}^{MM})$.
\end{itemize}
\end{lemma}

\begin{proof}
It is easy to check that if $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$,
a RM player plays action $I$ in $G^{C}$; that if $b^{G^{C}}-d^{G^{C}}<c^{G^{C}}-a^{G^{C}}$,
RM plays $II$; and that if $b^{G^{C}}-d^{G^{C}}=c^{G^{C}}-a^{G^{C}}$,
a RM player is indifferent between $I$ and $II$ in $G^{C}$, and
we assume that randomizes with $(\frac{1}{2}I;\frac{1}{2}II)$. Similarly,
if $a^{G^{A}}-c^{G^{A}}>d^{G^{A}}-b^{G^{A}}$, a RM player plays action
$I$ in $G^{A}$; if $a^{G^{A}}-c^{G^{A}}<d^{G^{A}}-b^{G^{A}}$, RM
plays $II$; and if $a^{G^{A}}-c^{G^{A}}=d^{G^{A}}-b^{G^{A}}$, a
RM player is indifferent between $I$ and $II$ in $G^{A}$, and randomizes
with $(\frac{1}{2}I;\frac{1}{2}II)$. Consequently, if $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$,
then $P(I_{G^{C}}^{RM})=1$, and by definition of $\phi$ we have
$P(II_{\phi(G^{C})}^{RM})=1$. Likewise, if $b^{G^{C}}-d^{G^{C}}<c^{G^{C}}-a^{G^{C}}$,
then $P(II_{G^{C}}^{RM})=1=P(I_{\phi(G^{C})}^{RM})$; and if $b^{G^{C}}-d^{G^{C}}=c^{G^{C}}-a^{G^{C}}$,
then $P(I_{G^{C}}^{RM})=P(II_{G^{C}}^{RM})=\frac{1}{2}=P(II_{\phi(G^{C})}^{RM})=P(I_{\phi(G^{C})}^{RM})$. \\
In the same way, in coordination games we have that if $b^{G^{C}}>c^{G^{C}}$,
a MM player plays $I$; if $c^{G^{C}}>b^{G^{C}}$, a MM player plays
$II$; and if $b^{G^{C}}=c^{G^{C}}$, MM is indifferent between $I$
and $II$, and plays $(\frac{1}{2}I;\frac{1}{2}II)$. In anti-coordination
games instead, if $a^{G^{A}}>d^{G^{A}}$, MM plays $I$; if $a^{G^{A}}<d^{G^{A}}$,
MM plays $II$; if $a^{G^{A}}=d^{G^{A}}$, MM plays $(\frac{1}{2}I;\frac{1}{2}II)$.
By definition of $\phi$: $P(I_{G^{C}}^{MM})=1=P(II_{\phi(G^{C})}^{MM})$
if $b^{G^{C}}>c^{G^{C}}$; $P(II_{G^{C}}^{MM})=1=P(I_{\phi(G^{C})}^{MM})$
if $c^{G^{C}}>b^{G^{C}}$; and $P(I_{G^{C}}^{MM})=P(II_{G^{C}}^{MM})=\frac{1}{2}=P(II_{\phi(G^{C})}^{MM})=P(I_{\phi(G^{C})}^{MM})$
if $b^{G^{C}}=c^{G^{C}}$.
\end{proof}

\medskip{}

\begin{lemma}
$P(\phi(G^{C}))=P(G^{C})$.
\end{lemma}

\begin{proof}
By definition, each game $G^{C}\equiv(a^{G^{C}},b^{G^{C}},c^{G^{C}},d^{G^{C}})$
is such that $a^{G^{C}}>c^{G^{C}}$ and $d^{G^{C}}>b^{G^{C}}$, and
each game $G^{A}\equiv(a^{G^{A}},b^{G^{A}},c^{G^{A}},d^{G^{A}})$
is such that $a^{G^{A}}<c^{G^{A}}$ and $d^{G^{A}}>b^{G^{A}}$. Since
$a,b,c,d$ come from i.i.d. sampling, by simple renaming of variables
it is clear that the probability of $(a^{G^{C}},b^{G^{C}},c^{G^{C}},d^{G^{C}})$
is equal to the probability of $(c^{G^{C}},d^{G^{C}},a^{G^{C}},b^{G^{C}})$.
Hence, $P(\phi(G^{C}))=P(G^{C})$.
\end{proof}

\medskip{}

\begin{lemma}
It holds that:
\begin{itemize}
\item $a^{G^{C}}>d^{G^{C}}\rightarrow(I_{G^{C}}^{MM}\subset I_{G^{C}}^{RM})$;
\item $a^{G^{C}}<d^{G^{C}}\rightarrow(II_{G^{C}}^{MM}\subset II_{G^{C}}^{RM})$;
\item $a^{G^{C}}=d^{G^{C}}\rightarrow I_{G^{C}}^{MM}=I_{G^{C}}^{RM}$.
\end{itemize}
\end{lemma}

\begin{proof}
If $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$, RM plays
$I$, and if $b^{G^{C}}-d^{G^{C}}=c^{G^{C}}-a^{G^{C}}$, RM plays
$(\frac{1}{2}I;\frac{1}{2}II)$, whereas if $b^{G^{C}}>c^{G^{C}}$,
MM plays $I$, and if $b^{G^{C}}=c^{G^{C}}$, MM plays $(\frac{1}{2}I;\frac{1}{2}II)$.
Then, $I_{G^{C}}^{RM}$ implies that $b^{G^{C}}-d^{G^{C}}\geq c^{G^{C}}-a^{G^{C}}$,
and $I_{G^{C}}^{MM}$ implies that $b^{G^{C}}\geq c^{G^{C}}$. Moreover,
on the assumption that $a^{G^{C}}>d^{G^{C}}$, it is easy to check
that $b^{G^{C}}\geq c^{G^{C}}$ implies $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$.
Hence, in any $G^{C}$ with $a^{G^{C}}>d^{G^{C}}$ it holds that $I_{G^{C}}^{MM}\mbox{ implies }I_{G^{C}}^{RM}$,
i.e., $a^{G^{C}}>d^{G^{C}}\rightarrow(I_{G^{C}}^{MM}\subseteq I_{G^{C}}^{RM})$.
Instead, it is possible that $a^{G^{C}}>d^{G^{C}}$, $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$
and $b^{G^{C}}<c^{G^{C}}$ hold simultaneously, so that $I_{G^{C}}^{MM}\nsupseteq I_{G^{C}}^{RM}$.
Consequently: $a^{G^{C}}>d^{G^{C}}\rightarrow(I_{G^{C}}^{MM}\subset I_{G^{C}}^{RM})$.
By symmetric argument it can be shown that $a^{G^{C}}<d^{G^{C}}\rightarrow(II_{G^{C}}^{MM}\subset II_{G^{C}}^{RM})$
too. \\
Finally, when $a^{G^{C}}=d^{G^{C}}$ it holds that: $b^{G^{C}}-d^{G^{C}}>c^{G^{C}}-a^{G^{C}}$
iff $b^{G^{C}}>c^{G^{C}}$; $b^{G^{C}}-d^{G^{C}}<c^{G^{C}}-a^{G^{C}}$
iff $b^{G^{C}}<c^{G^{C}}$; and $b^{G^{C}}-d^{G^{C}}=c^{G^{C}}-a^{G^{C}}$
iff $b^{G^{C}}=c^{G^{C}}$. Hence, $a^{G^{C}}=d^{G^{C}}\rightarrow I_{G^{C}}^{MM}=I_{G^{C}}^{RM}$.
\end{proof}

\medskip{}


We are now ready to prove that: 
\begin{itemize}
\item[(i')] $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,RM)>EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,RM);$
\item[(ii')] $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,MM)<EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,MM).$
\end{itemize}
We can rewrite $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,RM)>EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,RM)$
more explicitly as:

\medskip{}

\noindent $\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{MM})\cdot a^{C}+P(II_{G^{C}}^{MM})\cdot d^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{MM})\cdot a^{A}+P(II_{G^{A}}^{MM})\cdot d^{A}]<\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{MM}\cap II_{G^{C}}^{RM})\cdot d^{C}+P(I_{G^{C}}^{MM}\cap II_{G^{C}}^{RM})\cdot c^{C}+P(II_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot b^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{MM}\cap I_{G^{A}}^{RM})\cdot a^{A}+P(II_{G^{A}}^{MM}\cap II_{G^{A}}^{RM})\cdot d^{A}+P(I_{G^{A}}^{MM}\cap II_{G^{A}}^{RM})\cdot c^{A}+P(II_{G^{A}}^{MM}\cap I_{G^{A}}^{RM})\cdot b^{A}]$

\medskip{}

\noindent Then, the next derivation follows. By Lemma 5 and 6, we can express
everything in terms of $G^{C}$ only: 
\begin{itemize}
\item $\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{RM})\cdot d^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{RM})\cdot a^{A}+P(II_{G^{A}}^{RM})\cdot d^{A}]>\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot a^{C}+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot d^{C}+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot c^{C}+P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot b^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{RM}\cap I_{G^{A}}^{MM})\cdot a^{A}+P(II_{G^{A}}^{RM}\cap II_{G^{A}}^{MM})\cdot d^{A}+P(I_{G^{A}}^{RM}\cap II_{G^{A}}^{MM})\cdot c^{A}+P(II_{G^{A}}^{RM}\cap I_{G^{A}}^{MM})\cdot b^{A}]$
\item $\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{RM})\cdot d^{C}+P(II_{G^{C}}^{RM})\cdot c^{C}+P(I{}_{G^{C}}^{RM})\cdot b^{C}]>\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot a^{C}+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot d^{C}+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot c^{C}+P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot b^{C}+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot c^{C}+P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot b^{C}+P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot a^{C}+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot d^{C}]$
\item $\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{RM})\cdot d^{C}+P(II_{G^{C}}^{RM})\cdot c^{C}+P(I{}_{G^{C}}^{RM})\cdot b^{C}]>\sum_{G^{C}}P(G^{C})[a^{C}\cdot(P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})+P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM}))+b^{C}\cdot(P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})+P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM}))+c^{C}\cdot(P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))+d^{C}\cdot(P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))]$
\end{itemize}
Now let us split into $a>d$ and $a<d$, and consider $a>d$ first.
Notice that, by Lemma 7, the case $a=d$ is irrelevant in order to
discriminate between RM and MM. If $a>d$, by Lemma 7 we can eliminate
the cases where RM plays $II$ and MM plays $I$:
\begin{itemize}
\item $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})[P(I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{RM})\cdot d^{C}+P(II_{G^{C}}^{RM})\cdot c^{C}+P(I{}_{G^{C}}^{RM})\cdot b^{C}]>\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})[a^{C}\cdot P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})+b^{C}\cdot P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})+c^{C}\cdot(P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))+d^{C}\cdot(P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))]$
\item $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})[P(I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{RM})\cdot d^{C}+P(II_{G^{C}}^{RM})\cdot c^{C}+P(I{}_{G^{C}}^{RM})\cdot b^{C}-a^{C}\cdot P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})-b^{C}\cdot P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})-c^{C}\cdot(P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))-d^{C}\cdot(P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))]>0$
\item $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})[a^{C}\cdot(P(I_{G^{C}}^{RM})-P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM}))+b^{C}\cdot(P(I{}_{G^{C}}^{RM})-P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM}))+c^{C}\cdot(P(II_{G^{C}}^{RM})-P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})-P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))+d^{C}\cdot(P(II_{G^{C}}^{RM})-P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})-P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}))]>0$
\end{itemize}
By Lemma 7, it is easy to check that $P(I_{G^{C}}^{RM})-P(I_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})=P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})$
and $P(II_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})=P(II_{G^{C}}^{RM})$.
Consequently, we have:
\begin{itemize}
\item $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})[a^{C}\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})+b^{C}\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})-c^{C}\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})-d^{C}\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})]>0$
\item $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot[a^{G^{C}}-c^{G^{C}}]>\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot[d^{G^{C}}-b^{G^{C}}]$.
\end{itemize}
\medskip{}

\noindent We know that $I_{G^{C}}^{RM}$ implies that $b^{G^{C}}-d^{G^{C}}\geq c^{G^{C}}-a^{G^{C}}$,
and $II_{G^{C}}^{MM}$ implies that $b^{G^{C}}\leq c^{G^{C}}$. From
$b^{G^{C}}-d^{G^{C}}\geq c^{G^{C}}-a^{G^{C}}$, it is easy to see
that $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot[a^{G^{C}}-c^{G^{C}}]\geq\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM})\cdot[d^{G^{C}}-b^{G^{C}}]$
holds. When the event $I_{G^{C}}^{RM}\cap II_{G^{C}}^{MM}$ obtains
on the assumption that $a^{G^{C}}>d^{G^{C}}$, there are only three
possible payoff orderings: $a>c\geq d>b$, $a>d>c>b$, and $a>d>c=b$.
If games are randomly sampled from a finite set with i.i.d. values
for $a,b,c$ and $d$, then $a>d>c=b$ occurs with positive probability,
and the last formula of the derivation holds with strict inequality
too. Hence, RM is evolutionarily stable when the value set for $a,b,c,d$
is finite. \\
If i.i.d. values are sampled from a compact and convex set instead,
it is again easy to see that $\forall a,d,c\ \exists\epsilon$ such
that $\forall b\in(d,d+\epsilon)$ the above formula holds with strict
inequality. We can simply take $\epsilon\equiv\frac{a-c}{2}$, and
the interval $(d,d+\epsilon)$ always has positive probability. Hence,
RM is evolutionarily stable when the value set for $a,b,c,d$ is a
compact and convex set too. \\
Symmetrically, from $a<d$ in the above derivation we get:

\medskip{}

\noindent $\sum_{G_{a<d}^{C}}P(G_{a<d}^{C})\cdot P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot[d^{C}-b^{C}]>\sum_{G_{a<d}^{C}}P(G_{a<d}^{C})\cdot P(II_{G^{C}}^{RM}\cap I_{G^{C}}^{MM})\cdot[a^{C}-c^{C}]$

\medskip{}

\noindent and the same argument follows.

\medskip{}

The second half of the result is that MM is not evolutionarily stable
against RM in $\mathcal{G}^{C}\cup\mathcal{G^{A}}$: $EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(MM,MM)<EU_{\mathcal{G}^{C}\cup\mathcal{G^{A}}}(RM,MM)$.
As before, we write it more explicitly as:

\medskip{}


\noindent $\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{MM})\cdot a^{C}+P(II_{G^{C}}^{MM})\cdot d^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{MM})\cdot a^{A}+P(II_{G^{A}}^{MM})\cdot d^{A}]<\sum_{G^{C}}P(G^{C})[P(I_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot a^{C}+P(II_{G^{C}}^{MM}\cap II_{G^{C}}^{RM})\cdot d^{C}+P(I_{G^{C}}^{MM}\cap II_{G^{C}}^{RM})\cdot c^{C}+P(II_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot b^{C}]+\sum_{G^{A}}P(G^{A})[P(I_{G^{A}}^{MM}\cap I_{G^{A}}^{RM})\cdot a^{A}+P(II_{G^{A}}^{MM}\cap II_{G^{A}}^{RM})\cdot d^{A}+P(I_{G^{A}}^{MM}\cap II_{G^{A}}^{RM})\cdot c^{A}+P(II_{G^{A}}^{MM}\cap I_{G^{A}}^{RM})\cdot b^{A}]$.
\medskip{}

\noindent Similarly to the above derivation, in the end we get: 

\medskip{}

\noindent $\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(II_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot[c^{G^{C}}-a^{G^{C}}]<\sum_{G_{a>d}^{C}}P(G_{a>d}^{C})\cdot P(II_{G^{C}}^{MM}\cap I_{G^{C}}^{RM})\cdot[b^{G^{C}}-d^{G^{C}}]$.

\medskip{}


\noindent Finally, by the same argument as before we can conclude that MM is
not evolutionarily stable against RM both when the value set for $a,b,c,d$
is finite, and when the value set for $a,b,c,d$ is a compact and
convex set. This concludes the proof. $\dashv$

\printbibliography[heading=bibintoc]


\newpage

\section{Snippets}

[More precisely, from the meta-game perspective many possible subjective
transformations of the objective utility are eliminated by evolution, but we find some
evolutionarily stable subjective utility maximizers whose utility does not coincide with the
objective evolutionary utility. This result leaves some room in between the two extrema: we can
understand rationality in a normative way, given by evolution, without having to discard all
the possible subjective utility representations as irrational. CHANGE PLACE OF THIS MAYBE]



\subsection{Version 2}

The importance of aiming at a richer evolutionary game theory has been recently emphasized by many works in theoretical biology and behavioral ecology [Fawcett\&al., McNamara, etc.]. The biological argument to embrace this goal is related to the criticisms towards the so-called behavioral gambit [Fawcett\&al.]. The behavioral gambit denotes the standard approach in evolutionary game theory that puts the focus of attention on the expressed behavior, and neglects the underlying mechanisms that generate that behavior. From this point of view, the benefit and the reliability coming from the use of evolutionary game theory for biological purposes is also under attack. There are good reasons to claim that focusing on the general psychological mechanisms instead of on behavior itself as the phenotype under evolutionary selection can be more faithful and insightful for natural biology and ecology [Fawcett\&al.].
Standard evolutionary game theory normally models the agents as playing a single fixed game, and as genetically predetermined to play fixed strategies, that consequently are the only target of natural selection in those frameworks. Standard models of evolutionary game theory cannot take charge of this shift of perspective until they will keep modelling a single game at a time, and until they will keep focusing on actions considered genetically encoded and fixed. ''Instead we should expect animals to have evolved a set of psychological mechanisms which enable them to perform well on average across a range of different circumstances''[Fawcett\&al.].

Attempts to overcome the behavioral gambit have recently been developed in economic literature too. In the last twenty years economists have been using evolutionary game-theoretical models to study evolution of preferences [cite], instead of evolution of behavior only. This approach is called indirect evolutionary approach, because players' behavior and actions stem from their subjective preferences, and it is aimed at investigating what subjective preferences are evolutionarily better off and robust with respect to natural selection. This shift from a direct evolutionary approach about observed actions and behavior to an indirect evolutionary approach takes only partly into account the behavioral gambit criticized by biologists and ecologists. The reason is that the models of evolution of preferences usually consider only one game at a time. This means that there is a single type of interaction that is supposed to drive the whole evolution of preferences: preferences are selected on the basis of one possible interaction only. Clearly, this approach does not take into consideration the variety of possible circumstances that animals are supposed to face during their lifetime. 

The meta-game model we propose pays heed to both components of the behavioral gambit. We retain the indirect evolutionary approach, but our agents in the population play over a class of possible games $\mathcal{G}$. In this way we explicitly model a range of different circumstances, as wished by theoretical biologists.  Consequently, each agent in the population does not represent either a simple behavior or a subjective preference, but a more general player type that associates a subjective preference for each game in the class $\mathcal{G}$. The player type is supposed to encode the general psychological mechanisms that generate the behavior for any possible interaction in $\mathcal{G}$. These general psychological mechanisms then become the target of evolution, and they are selected based on the average fitness over a class of different interactions. 

In particular, in the following we mainly deal with two types of agents: players whose subjective preference coincides with the evolutionary fitness, and players whose subjective preference is defined in terms of regret. It turns out that psychological mechanisms and subjective conceptualizations based on regret can outperform more veridical conceptualizations coinciding with the evolutionary fitness.
This is just an example of the kind of insights and results that we can gain by adopting a meta-game perspective and by shifting the focus of our attention to psychological mechanisms and subjective conceptualizations as the phenotype under selection.


-maybe to add: difference with learning. Fawcett\&al. talk more about differences in learning, whereas we model differences in subjective conceptualizations.


[A pivotal element of economics and decision theory is the definition of rationality as
maximization of subjective preferences.]



\begin{itemize}
\item We present an approach to studying evolutionary selection of \emph{choice principles},
  i.e., ways of choosing consistently across several games. In other words, we would like to
  look at the problem of ``rational choice'' from an evolutionary point of view: what choice
  principles would be promoted, which demoted in evolutionary competition amongst each other?

\item This depends on the environment; it depends on what choice situations occur how
  frequently. Maybe some choice principle is better in some situations, while another one is
  better in others. 


\item We argue that this ``meta-evolutionary'' approach could eventually help explain attested
  deviations of human decision making from the classical ideal: choice behavior evolved to be
  an ``ecologically rational'', near-optimal adaptation to the environment
  \citep{Anderson1990:The-Adaptive-Ch,Anderson1991:Is-human-cognit,GigerenzerGoldstein1996:Reasoning-the-F,ChaterOaksford2000:The-Rational-An}. This
  is inline with recent aspirations to provide an evolutionary rationale for decision making
  processes
  \citep[e.g.][]{HammersteinStevens2012:Six-Reasons-for,FawcettHamblin2013:Exposing-the-be}. Here,
  we seek to contribute to the formal machinery, an extension of evolutionary game theory, that
  allows to capture statistical properties of the environment
  \citep[cf.][]{McNamara2013:Towards-a-Riche}.
\end{itemize}



\subsection{The environment: meta-games}

\begin{itemize}
\item imagine huge, virtually infinite population of agents, each carrying a choice principle
\item agents play a randomly sampled game against a randomly sampled opponent
\item fitness is based on the average payoff of choice principle A against choice principle B,
  taken over arbitrary games $g$ and weighted their occurrence probability $P(g)$:
  $\int_g P(g) \times U_g(\text{CP-A}, \text{CP-B}) \text{d}g$
\item the occurrence probability of games $g$ is the ``environment'' and, possibly, impossible to
  derive theoretically, or to measure empirically
\item here, use a relatively neutral approach instead that is practicable:
  \begin{itemize}
  \item games are individuated by their payoff matrices (no framing effects or similar)
  \item each entry in a payoff matrix is an i.~i.~d.~random variable
    \begin{itemize}
    \item approach still incorporates a bias (e.g., against strategic form representations of
      sequential games)
    \end{itemize}
  \end{itemize}
\item example: average payoffs from numerical simulation of ($2 \times 2$ symmetric games)
\item example: average payoffs from numerical simulation of ($n \times n$ symmetric games, with
  $n$ uniformly random (up to some upper-bound))
\end{itemize}


\begin{itemize}
\item Evolutionary game theory has become an established philosophical tool for probing into
  conceptual issues whose complexity requires mathematical modeling.
  \begin{itemize}
  \item helped structure debate about foraging, mating, evolution of cooperation,
    information-flow, deception etc.
  \end{itemize}
\item Most applications of EGT look at evolutionary selection of behavior in a single
  game. There are two crude simplifications here:
  \begin{enumerate}
  \item The stage game is usually considered fixed, closed and immutable.
    \begin{itemize}
    \item there are some notable exceptions where the game is open ended, e.g., by the
      invention of actions \citep{WordenLevin2007:Evolutionary-es,
        McKenzie-AlexanderSkymrs2012:Inventing-New-S}
    \end{itemize}
  \item What evolves are behavioral strategies for the stage game \citep[what][call the
    ``behavioral gamit'']{FawcettHamblin2013:Exposing-the-be} \myalert{(more references!
      Gigerenzer etc.)}.
  \end{enumerate}
\item It has been argued that we should rather study the evolutionary selection of \emph{choice
    mechanisms} that are adapted in a rich and variable environment
  \citep[e.g.][]{FawcettHamblin2013:Exposing-the-be,McNamara2013:Towards-a-Riche}.
\item However, studies on the adaptive value of choice mechanisms have focused, for the most
  part, on the evolutionary benefit of learning rules
  \citep[e.g.][]{ZollmanSmead2010:Plasticity-and-,SmeadZollman2013:The-Stability-o}. (\myalert{More references Harley 1981!!!, \dots}). 
    Moreover, only little attention has been paid to
  modeling the direct (game-theoretic) meta-competition between alternative choice mechanisms
  \citep[see][for related criticism]{FawcettHamblin2013:Exposing-the-be}.
\item Here, we would like to make two contributions to the literature on evolution of choice
  mechanisms:
  \begin{enumerate}
  \item On the conceptual side, we argue that paying attention to the evolution of (subjective
    representations of) preferences matters. Since almost any reasonable learning or
    decision-making process will make use of some (subjective, agent-internal (possibly
    unconscious)) representation of the quality of choice options, the question of which such
    representations are ecologically valuable (i.e., lead to high fitness) is central. In fact,
    the evolution of (subjective representations of) preferences has recently been studied in
    theoretical economics as well \myalert{add references}. However, these studies also suffer
    from the ``behavioral gambit'' and the usual shortcomings of the closedness of the stage game. 
  \item On the methodological side, we therefore introduce a conservative extension of the
    standard EGT that allows us to reuse notions such as evolutionary stability / evolutionary
    dynamics and yet helps us study the evolutionary competition between choice mechanisms in a
    statistically variable environment. Concretely, we look at the evolutionary competition of
    choice mechanisms in a ``meta-game'' that consists of the average expected payoffs of
    choice mechanisms when playing arbitrary games (from a given class). In this sense, a
    meta-game captures (the modeller's) assumptions about the relevant statistic of the
    environment in which evolutionary forces operate.
  \end{enumerate}
\item To drive home our conceptual point that preference representations can matter, we try to
  isolate, as good as we can, the evolution of preferences from considerations of learning or
  other factors feeding a decision mechanism (such as the acquisition of ecologically useful
  representations (think: beliefs)). (Obviously, eventually, we would like to study the
  evolution of all of these relevant components in one swoop.)
\item To demonstrate how this approach can be theoretically rewarding, we show that, under
  reasonable additional assumptions, evolutionary selection can support non-veridical
  representations of payoffs in terms of regret.
  \begin{itemize}
  \item We argue that this ``meta-evolutionary'' approach could eventually help explain
    attested deviations of human decision making from the classical ideal: choice behavior
    evolved to be an ``ecologically rational'', near-optimal adaptation to the environment
    \citep{Anderson1990:The-Adaptive-Ch,Anderson1991:Is-human-cognit,GigerenzerGoldstein1996:Reasoning-the-F,ChaterOaksford2000:The-Rational-An}. This
    is inline with recent aspirations to provide an evolutionary rationale for decision making
    processes
    \citep[e.g.][]{HammersteinStevens2012:Six-Reasons-for,FawcettHamblin2013:Exposing-the-be}.
  \item Non-veridical regret-based representations of payoffs are intuitively appealing (we do,
    at least on occasion, care about counterfactual or hypothetical losses), but could also
    help explain, for instance, that decision-makers may violate the independence axiom: human
    and non-human decision makers can favor $A$ when presented with a choice
    between $A$ and $B$, but prefer $B$ when presented with $A$, $B$ and $C$ \myalert{(for
      animals cite from Fawcett page 3)} \myalert{(add
      citation for human performance)}
  \item We need to be careful here: we do not want to stress that this approach here (the
    particular implemenation of a regret-based choice mechanism) explains these empirical
    findings (better than any other line of explanation). Our point is more general and
    methodological. Evolution of preferences is something that the literature on evolution of
    choice mechanisms should care about. We also presented a method that can be useful and an
    example of that method that should (succinctly) demonstrate our aforementioned conceptual
    point that evolution of preferences is conceptually important and can give non-trivial,
    unexpected and philosophically useful results.
  \end{itemize}
\item contributes to: (i) methodological reflection on evolutionary game theory, (ii) ecological
  rationality of choice behavior, (iii) evolution of preferences literature
\end{itemize}




\end{document}



